{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "xlmroberta_twitter_sentiment_analysis_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0bc1782cd264c0488447fa4378d4e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5cc02a1924d7431b94db319f3e3c1356",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eaa4b564a35b4c05b2b8e4258528a81d",
              "IPY_MODEL_7d9a96755e4d4606bc928a4c3ff71948"
            ]
          }
        },
        "5cc02a1924d7431b94db319f3e3c1356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaa4b564a35b4c05b2b8e4258528a81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2f89bd2da2814f4cb8e3c4a66107d937",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7f586bce0d74a98a14f4ed04f74c07b"
          }
        },
        "7d9a96755e4d4606bc928a4c3ff71948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb79c85af94f43458bb465675ee8ecb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 36.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95853ae2ff0f4fd5b6360b06ab13635b"
          }
        },
        "2f89bd2da2814f4cb8e3c4a66107d937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7f586bce0d74a98a14f4ed04f74c07b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb79c85af94f43458bb465675ee8ecb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95853ae2ff0f4fd5b6360b06ab13635b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48dce98b87c84f208749a3d29d98ab02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65ee121626b940cda617ddf1ec9e3bb3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_892b713ca8174a8286fcb632575484f7",
              "IPY_MODEL_db74b34e5c9944fba06c8a5a1fae9fe3"
            ]
          }
        },
        "65ee121626b940cda617ddf1ec9e3bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "892b713ca8174a8286fcb632575484f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c85da184e0e04604bbba125c2e639220",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_744b5a0a41c94d49931bee597e01427b"
          }
        },
        "db74b34e5c9944fba06c8a5a1fae9fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb438d983a4249a1b7add2fe5c5ad8fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:27&lt;00:00, 18.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb78c5f486d14da88b9262008d7008a7"
          }
        },
        "c85da184e0e04604bbba125c2e639220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "744b5a0a41c94d49931bee597e01427b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb438d983a4249a1b7add2fe5c5ad8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb78c5f486d14da88b9262008d7008a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8767660341954ac3b6b14a2088525eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_baeb341e208f46bc942a4c0442a421a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a21d764a8f7a4401b301517ef5b14a57",
              "IPY_MODEL_2d68a05a992743a8a8facca037c13712"
            ]
          }
        },
        "baeb341e208f46bc942a4c0442a421a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a21d764a8f7a4401b301517ef5b14a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b94292544456405685450c746f9b0a67",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb75b073504a48cb9dd480df59d58120"
          }
        },
        "2d68a05a992743a8a8facca037c13712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05ef536b9b73490cae49c4c8f73736dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:27&lt;00:00, 40.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_692fa1fda5f34b309bd753a02ff0f15f"
          }
        },
        "b94292544456405685450c746f9b0a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb75b073504a48cb9dd480df59d58120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ef536b9b73490cae49c4c8f73736dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "692fa1fda5f34b309bd753a02ff0f15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA8dWgqBqcD-"
      },
      "source": [
        "#Install dependencies\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYAcxU75D5J8",
        "outputId": "3bd2078b-7802-4741-a615-07ec02abd840"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "   \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NYS-pZcD_AE",
        "outputId": "5326582c-4b4a-4960-c5ee-2bc713e1b74e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 25.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 25.4MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 19.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 15.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 15.9MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 15.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 15.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 14.8MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 52.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=d34a617854e95d6333e2c6d703bb51e1e9d72772f9c4aca5d4153ff654e5f4f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9haTIzc6UuKo",
        "outputId": "5d933fea-d0b5-4b0a-d6ff-a937c0896492"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s9G4m1-UxRV",
        "outputId": "22b6c225-90dd-49c7-9d03-63b2a99377eb"
      },
      "source": [
        "!ls /gdrive/MyDrive/twitter_sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "french_tweets.csv     twitter_sentiment_bert_full.csv\n",
            "french_tweets_me.csv  twitter_sentiment_bert_med.csv\n",
            "model_save\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJa2jHVKqh6s"
      },
      "source": [
        "#Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "3vS60xKFEFwL",
        "outputId": "9df61a49-49d2-4f64-afcb-4be157df44cf"
      },
      "source": [
        "#loading the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# better display of review text in dataframes\n",
        "pd.set_option('display.max_colwidth', None) \n",
        "\n",
        "#df=pd.read_csv('./twitter_sentiment_bert.csv',encoding=\"ISO-8859-1\",names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
        "df1=pd.read_csv('/gdrive/MyDrive/twitter_sentiment/french_tweets_me.csv')\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>613362</td>\n",
              "      <td>0</td>\n",
              "      <td>Whoops! Pardon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>613363</td>\n",
              "      <td>0</td>\n",
              "      <td>Je l'ai vu, mais je ne les ai jamais vus dans les magasins d'alimentation ici, je vais devoir regarder mieux la prochaine fois que je vais faire du shopping. Merci!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>613364</td>\n",
              "      <td>0</td>\n",
              "      <td>Dernier jour ko ng mobwars insider huhuhu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>613365</td>\n",
              "      <td>0</td>\n",
              "      <td>Je ne peux vraiment pas dormir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>613366</td>\n",
              "      <td>0</td>\n",
              "      <td>Je suis envahie par les moustiques géants. Quelle soirée de houle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299995</th>\n",
              "      <td>913357</td>\n",
              "      <td>1</td>\n",
              "      <td>C'est sérieusement.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299996</th>\n",
              "      <td>913358</td>\n",
              "      <td>1</td>\n",
              "      <td>Nous sommes allés aux fantômes des petites amies après que c'était bon et que dani a apporté son petit ami et des amis de somme, c'était vraiment amusant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299997</th>\n",
              "      <td>913359</td>\n",
              "      <td>1</td>\n",
              "      <td>Brandon !!! Où es-tu? &amp; Lt; ~ kc ~ &amp; gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299998</th>\n",
              "      <td>913360</td>\n",
              "      <td>1</td>\n",
              "      <td>- Qu'est-ce que c'est? J'ai besoin de plus d'informations!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299999</th>\n",
              "      <td>913361</td>\n",
              "      <td>1</td>\n",
              "      <td>A eu une belle journée avec sis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                                                                                                                                                  text\n",
              "0           613362  ...                                                                                                                                                        Whoops! Pardon\n",
              "1           613363  ...  Je l'ai vu, mais je ne les ai jamais vus dans les magasins d'alimentation ici, je vais devoir regarder mieux la prochaine fois que je vais faire du shopping. Merci!\n",
              "2           613364  ...                                                                                                                             Dernier jour ko ng mobwars insider huhuhu\n",
              "3           613365  ...                                                                                                                                        Je ne peux vraiment pas dormir\n",
              "4           613366  ...                                                                                                     Je suis envahie par les moustiques géants. Quelle soirée de houle\n",
              "...            ...  ...                                                                                                                                                                   ...\n",
              "299995      913357  ...                                                                                                                                                   C'est sérieusement.\n",
              "299996      913358  ...             Nous sommes allés aux fantômes des petites amies après que c'était bon et que dani a apporté son petit ami et des amis de somme, c'était vraiment amusant\n",
              "299997      913359  ...                                                                                                                              Brandon !!! Où es-tu? & Lt; ~ kc ~ & gt;\n",
              "299998      913360  ...                                                                                                            - Qu'est-ce que c'est? J'ai besoin de plus d'informations!\n",
              "299999      913361  ...                                                                                                                                       A eu une belle journée avec sis\n",
              "\n",
              "[300000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "DMBTcC3clnGs",
        "outputId": "c1840d5c-e90c-440a-fbf7-35905b92d922"
      },
      "source": [
        "df2=pd.read_csv('/gdrive/MyDrive/twitter_sentiment/twitter_sentiment_bert_med.csv')\n",
        "df2.rename(columns={'target':'label'},inplace=True)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>700000</td>\n",
              "      <td>0</td>\n",
              "      <td>People are tweeting advice on how to combat tear gas in Iran.    #iranelection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>700001</td>\n",
              "      <td>0</td>\n",
              "      <td>can't go 2 the anberlin show 2nite, tickets sold out before doc gave approval.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>700002</td>\n",
              "      <td>0</td>\n",
              "      <td>Woke up with lots of wisdom teeth drama..Gotta get these things removed soon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>700003</td>\n",
              "      <td>0</td>\n",
              "      <td>@tom_teel Not yet dude... Gonna have to buy a new one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>700004</td>\n",
              "      <td>0</td>\n",
              "      <td>everytime i fall asleep my dreams are haunted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>899995</td>\n",
              "      <td>1</td>\n",
              "      <td>@jvdouglas  haha, no, the remark on maternity leave fired me up a little</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>899996</td>\n",
              "      <td>1</td>\n",
              "      <td>@altitis and to you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>899997</td>\n",
              "      <td>1</td>\n",
              "      <td>Okie doke!! Time for me to escape for the North while Massa's back is turned. Be on when I get home folks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>899998</td>\n",
              "      <td>1</td>\n",
              "      <td>finished the lessons, hooray!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>899999</td>\n",
              "      <td>1</td>\n",
              "      <td>Some ppl are just fucking KP0. Cb ! Stop asking me laa.. I love my boyfriend and thats it.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                                                                                        text\n",
              "0           700000  ...                              People are tweeting advice on how to combat tear gas in Iran.    #iranelection\n",
              "1           700001  ...                             can't go 2 the anberlin show 2nite, tickets sold out before doc gave approval. \n",
              "2           700002  ...                              Woke up with lots of wisdom teeth drama..Gotta get these things removed soon. \n",
              "3           700003  ...                                                      @tom_teel Not yet dude... Gonna have to buy a new one \n",
              "4           700004  ...                                                              everytime i fall asleep my dreams are haunted \n",
              "...            ...  ...                                                                                                         ...\n",
              "199995      899995  ...                                   @jvdouglas  haha, no, the remark on maternity leave fired me up a little \n",
              "199996      899996  ...                                                                                       @altitis and to you! \n",
              "199997      899997  ...  Okie doke!! Time for me to escape for the North while Massa's back is turned. Be on when I get home folks \n",
              "199998      899998  ...                                                                              finished the lessons, hooray! \n",
              "199999      899999  ...                 Some ppl are just fucking KP0. Cb ! Stop asking me laa.. I love my boyfriend and thats it. \n",
              "\n",
              "[200000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "VVCmLWekl0Na",
        "outputId": "980d25ed-151f-49b1-e710-6dc749e3fc5d"
      },
      "source": [
        "df=df1.append(df2, ignore_index=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>613362</td>\n",
              "      <td>0</td>\n",
              "      <td>Whoops! Pardon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>613363</td>\n",
              "      <td>0</td>\n",
              "      <td>Je l'ai vu, mais je ne les ai jamais vus dans les magasins d'alimentation ici, je vais devoir regarder mieux la prochaine fois que je vais faire du shopping. Merci!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>613364</td>\n",
              "      <td>0</td>\n",
              "      <td>Dernier jour ko ng mobwars insider huhuhu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>613365</td>\n",
              "      <td>0</td>\n",
              "      <td>Je ne peux vraiment pas dormir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>613366</td>\n",
              "      <td>0</td>\n",
              "      <td>Je suis envahie par les moustiques géants. Quelle soirée de houle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>899995</td>\n",
              "      <td>1</td>\n",
              "      <td>@jvdouglas  haha, no, the remark on maternity leave fired me up a little</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499996</th>\n",
              "      <td>899996</td>\n",
              "      <td>1</td>\n",
              "      <td>@altitis and to you!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499997</th>\n",
              "      <td>899997</td>\n",
              "      <td>1</td>\n",
              "      <td>Okie doke!! Time for me to escape for the North while Massa's back is turned. Be on when I get home folks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>899998</td>\n",
              "      <td>1</td>\n",
              "      <td>finished the lessons, hooray!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>899999</td>\n",
              "      <td>1</td>\n",
              "      <td>Some ppl are just fucking KP0. Cb ! Stop asking me laa.. I love my boyfriend and thats it.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                                                                                                                                                  text\n",
              "0           613362  ...                                                                                                                                                        Whoops! Pardon\n",
              "1           613363  ...  Je l'ai vu, mais je ne les ai jamais vus dans les magasins d'alimentation ici, je vais devoir regarder mieux la prochaine fois que je vais faire du shopping. Merci!\n",
              "2           613364  ...                                                                                                                             Dernier jour ko ng mobwars insider huhuhu\n",
              "3           613365  ...                                                                                                                                        Je ne peux vraiment pas dormir\n",
              "4           613366  ...                                                                                                     Je suis envahie par les moustiques géants. Quelle soirée de houle\n",
              "...            ...  ...                                                                                                                                                                   ...\n",
              "499995      899995  ...                                                                                             @jvdouglas  haha, no, the remark on maternity leave fired me up a little \n",
              "499996      899996  ...                                                                                                                                                 @altitis and to you! \n",
              "499997      899997  ...                                                            Okie doke!! Time for me to escape for the North while Massa's back is turned. Be on when I get home folks \n",
              "499998      899998  ...                                                                                                                                        finished the lessons, hooray! \n",
              "499999      899999  ...                                                                           Some ppl are just fucking KP0. Cb ! Stop asking me laa.. I love my boyfriend and thats it. \n",
              "\n",
              "[500000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYCvCF0REVso",
        "outputId": "dd11913b-b37d-44c2-f74a-7acbbca46b9a"
      },
      "source": [
        "df.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    258242\n",
              "1    241758\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ygEQewGqGg"
      },
      "source": [
        "sentences = df.text.values\n",
        "labels= df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "32SW5c6wIM2w",
        "outputId": "b4cba992-09a0-4eec-8814-3e35b3db617c"
      },
      "source": [
        "'''y = np.bincount(labels)\n",
        "ii = np.nonzero(y)[0]\n",
        "list(zip(ii,y[ii]))'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'y = np.bincount(labels)\\nii = np.nonzero(y)[0]\\nlist(zip(ii,y[ii]))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ektpryDb8c0n",
        "outputId": "4d2806f0-89fe-43b4-93f7-7157608d2e2b"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 26.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 22.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 20.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 16.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 10.3MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 11.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 13.4MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 13.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHX2FsfJraES"
      },
      "source": [
        "#Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "a0bc1782cd264c0488447fa4378d4e6f",
            "5cc02a1924d7431b94db319f3e3c1356",
            "eaa4b564a35b4c05b2b8e4258528a81d",
            "7d9a96755e4d4606bc928a4c3ff71948",
            "2f89bd2da2814f4cb8e3c4a66107d937",
            "a7f586bce0d74a98a14f4ed04f74c07b",
            "cb79c85af94f43458bb465675ee8ecb4",
            "95853ae2ff0f4fd5b6360b06ab13635b"
          ]
        },
        "id": "Auk7pARF7hRH",
        "outputId": "fd3f01fe-8e16-446b-e63d-a3b6c5c6143f"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "# Load the XLMRobertaTokenizer tokenizer.\n",
        "print('Loading XLMRobertaTokenizer ...')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading XLMRobertaTokenizer ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0bc1782cd264c0488447fa4378d4e6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46evtvf4KsAO",
        "outputId": "52f0b03c-8097-4e12-cbd7-606814d7cb85"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Whoops! Pardon\n",
            "Tokenized:  ['▁Who', 'ops', '!', '▁Par', 'don']\n",
            "Token IDs:  [40469, 68818, 38, 2392, 4445]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe5hCa0PLCrk",
        "outputId": "b3f76507-9b4d-41b8-92cc-91a159818bde"
      },
      "source": [
        "#to get max length \n",
        "#train['comment_text'].apply(lambda x:len(str(x).split())).max()\n",
        "max_len=df['text'].apply(lambda x:len(tokenizer.encode(x,add_special_tokens=True))).max()\n",
        "print('Max sentence tokens: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence tokens:  267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "EieMX7qLfa_-",
        "outputId": "272fedd5-3cd2-4b34-9b75-c1446043fcaa"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f08704f97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xvZs-d0M7X1",
        "outputId": "0ab19258-3984-4ba9-8b1f-3590c8eb784a"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',   \n",
        "                        truncation=True\n",
        "                   )\n",
        "        \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Whoops! Pardon\n",
            "Token IDs: tensor([    0, 40469, 68818,    38,  2392,  4445,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irCdntUTvezO"
      },
      "source": [
        "#labels=[1 if i==4 else 0 for i in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRq3ErNDvpBn"
      },
      "source": [
        "#l=pd.DataFrame(labels)\n",
        "#l[0].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYF-We0SNtMO",
        "outputId": "ee4f947d-83b8-408e-846a-9585f3bc7af2"
      },
      "source": [
        "labels = torch.tensor(labels,dtype=torch.long)\n",
        "labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpMEGG1kT2o5"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "#print('{:>5,} training samples'.format(train_size))\n",
        "#print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya4YBLgIUEdJ"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zo4FwXKsBVm"
      },
      "source": [
        "#Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48dce98b87c84f208749a3d29d98ab02",
            "65ee121626b940cda617ddf1ec9e3bb3",
            "892b713ca8174a8286fcb632575484f7",
            "db74b34e5c9944fba06c8a5a1fae9fe3",
            "c85da184e0e04604bbba125c2e639220",
            "744b5a0a41c94d49931bee597e01427b",
            "fb438d983a4249a1b7add2fe5c5ad8fc",
            "eb78c5f486d14da88b9262008d7008a7",
            "8767660341954ac3b6b14a2088525eff",
            "baeb341e208f46bc942a4c0442a421a9",
            "a21d764a8f7a4401b301517ef5b14a57",
            "2d68a05a992743a8a8facca037c13712",
            "b94292544456405685450c746f9b0a67",
            "eb75b073504a48cb9dd480df59d58120",
            "05ef536b9b73490cae49c4c8f73736dc",
            "692fa1fda5f34b309bd753a02ff0f15f"
          ]
        },
        "id": "8tl4FuCaUZbD",
        "outputId": "31b6a20d-1c41-434e-ae8f-2380211160e2"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels = 2, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48dce98b87c84f208749a3d29d98ab02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8767660341954ac3b6b14a2088525eff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vV6fEf5VQSl"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ZXqoCjU4pF"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvpNdoVrVLY1"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9S3lBWhVZDU"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OqH_vNLVdFy",
        "outputId": "6dc8d96c-03c9-4470-eb83-313d39a74df0"
      },
      "source": [
        "for batch in train_dataloader:\n",
        "  print(batch[0],batch[2])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[     0,   1374,    177,  ...,      1,      1,      1],\n",
            "        [     0,   1374, 128897,  ...,      1,      1,      1],\n",
            "        [     0,    845,   5189,  ...,      1,      1,      1],\n",
            "        ...,\n",
            "        [     0,   1468,  31251,  ...,      1,      1,      1],\n",
            "        [     0,   1374,  72253,  ...,      1,      1,      1],\n",
            "        [     0,    541,    248,  ...,      1,      1,      1]]) tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
            "        1, 0, 1, 0, 1, 0, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkRloszxs0h6"
      },
      "source": [
        "#Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJEZUIEeVgIA",
        "outputId": "5d5395fb-37de-455f-d012-2f0f8975c620"
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=\"1\"\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 200\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "  \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss=outputs[0]\n",
        "        logits=outputs[1]\n",
        "        \n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                    labels=b_labels)\n",
        "            loss=outputs[0]\n",
        "            logits=outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  14,063.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  14,063.    Elapsed: 0:00:33.\n",
            "  Batch   120  of  14,063.    Elapsed: 0:00:50.\n",
            "  Batch   160  of  14,063.    Elapsed: 0:01:07.\n",
            "  Batch   200  of  14,063.    Elapsed: 0:01:24.\n",
            "  Batch   240  of  14,063.    Elapsed: 0:01:41.\n",
            "  Batch   280  of  14,063.    Elapsed: 0:01:58.\n",
            "  Batch   320  of  14,063.    Elapsed: 0:02:16.\n",
            "  Batch   360  of  14,063.    Elapsed: 0:02:34.\n",
            "  Batch   400  of  14,063.    Elapsed: 0:02:52.\n",
            "  Batch   440  of  14,063.    Elapsed: 0:03:09.\n",
            "  Batch   480  of  14,063.    Elapsed: 0:03:27.\n",
            "  Batch   520  of  14,063.    Elapsed: 0:03:45.\n",
            "  Batch   560  of  14,063.    Elapsed: 0:04:02.\n",
            "  Batch   600  of  14,063.    Elapsed: 0:04:20.\n",
            "  Batch   640  of  14,063.    Elapsed: 0:04:38.\n",
            "  Batch   680  of  14,063.    Elapsed: 0:04:55.\n",
            "  Batch   720  of  14,063.    Elapsed: 0:05:13.\n",
            "  Batch   760  of  14,063.    Elapsed: 0:05:31.\n",
            "  Batch   800  of  14,063.    Elapsed: 0:05:48.\n",
            "  Batch   840  of  14,063.    Elapsed: 0:06:06.\n",
            "  Batch   880  of  14,063.    Elapsed: 0:06:24.\n",
            "  Batch   920  of  14,063.    Elapsed: 0:06:41.\n",
            "  Batch   960  of  14,063.    Elapsed: 0:06:59.\n",
            "  Batch 1,000  of  14,063.    Elapsed: 0:07:17.\n",
            "  Batch 1,040  of  14,063.    Elapsed: 0:07:34.\n",
            "  Batch 1,080  of  14,063.    Elapsed: 0:07:52.\n",
            "  Batch 1,120  of  14,063.    Elapsed: 0:08:10.\n",
            "  Batch 1,160  of  14,063.    Elapsed: 0:08:27.\n",
            "  Batch 1,200  of  14,063.    Elapsed: 0:08:45.\n",
            "  Batch 1,240  of  14,063.    Elapsed: 0:09:03.\n",
            "  Batch 1,280  of  14,063.    Elapsed: 0:09:20.\n",
            "  Batch 1,320  of  14,063.    Elapsed: 0:09:38.\n",
            "  Batch 1,360  of  14,063.    Elapsed: 0:09:56.\n",
            "  Batch 1,400  of  14,063.    Elapsed: 0:10:13.\n",
            "  Batch 1,440  of  14,063.    Elapsed: 0:10:31.\n",
            "  Batch 1,480  of  14,063.    Elapsed: 0:10:49.\n",
            "  Batch 1,520  of  14,063.    Elapsed: 0:11:06.\n",
            "  Batch 1,560  of  14,063.    Elapsed: 0:11:24.\n",
            "  Batch 1,600  of  14,063.    Elapsed: 0:11:42.\n",
            "  Batch 1,640  of  14,063.    Elapsed: 0:11:59.\n",
            "  Batch 1,680  of  14,063.    Elapsed: 0:12:17.\n",
            "  Batch 1,720  of  14,063.    Elapsed: 0:12:35.\n",
            "  Batch 1,760  of  14,063.    Elapsed: 0:12:52.\n",
            "  Batch 1,800  of  14,063.    Elapsed: 0:13:10.\n",
            "  Batch 1,840  of  14,063.    Elapsed: 0:13:28.\n",
            "  Batch 1,880  of  14,063.    Elapsed: 0:13:45.\n",
            "  Batch 1,920  of  14,063.    Elapsed: 0:14:03.\n",
            "  Batch 1,960  of  14,063.    Elapsed: 0:14:20.\n",
            "  Batch 2,000  of  14,063.    Elapsed: 0:14:38.\n",
            "  Batch 2,040  of  14,063.    Elapsed: 0:14:56.\n",
            "  Batch 2,080  of  14,063.    Elapsed: 0:15:13.\n",
            "  Batch 2,120  of  14,063.    Elapsed: 0:15:31.\n",
            "  Batch 2,160  of  14,063.    Elapsed: 0:15:49.\n",
            "  Batch 2,200  of  14,063.    Elapsed: 0:16:06.\n",
            "  Batch 2,240  of  14,063.    Elapsed: 0:16:24.\n",
            "  Batch 2,280  of  14,063.    Elapsed: 0:16:42.\n",
            "  Batch 2,320  of  14,063.    Elapsed: 0:16:59.\n",
            "  Batch 2,360  of  14,063.    Elapsed: 0:17:17.\n",
            "  Batch 2,400  of  14,063.    Elapsed: 0:17:35.\n",
            "  Batch 2,440  of  14,063.    Elapsed: 0:17:52.\n",
            "  Batch 2,480  of  14,063.    Elapsed: 0:18:10.\n",
            "  Batch 2,520  of  14,063.    Elapsed: 0:18:28.\n",
            "  Batch 2,560  of  14,063.    Elapsed: 0:18:45.\n",
            "  Batch 2,600  of  14,063.    Elapsed: 0:19:03.\n",
            "  Batch 2,640  of  14,063.    Elapsed: 0:19:21.\n",
            "  Batch 2,680  of  14,063.    Elapsed: 0:19:38.\n",
            "  Batch 2,720  of  14,063.    Elapsed: 0:19:56.\n",
            "  Batch 2,760  of  14,063.    Elapsed: 0:20:14.\n",
            "  Batch 2,800  of  14,063.    Elapsed: 0:20:31.\n",
            "  Batch 2,840  of  14,063.    Elapsed: 0:20:49.\n",
            "  Batch 2,880  of  14,063.    Elapsed: 0:21:07.\n",
            "  Batch 2,920  of  14,063.    Elapsed: 0:21:24.\n",
            "  Batch 2,960  of  14,063.    Elapsed: 0:21:42.\n",
            "  Batch 3,000  of  14,063.    Elapsed: 0:22:00.\n",
            "  Batch 3,040  of  14,063.    Elapsed: 0:22:17.\n",
            "  Batch 3,080  of  14,063.    Elapsed: 0:22:35.\n",
            "  Batch 3,120  of  14,063.    Elapsed: 0:22:52.\n",
            "  Batch 3,160  of  14,063.    Elapsed: 0:23:10.\n",
            "  Batch 3,200  of  14,063.    Elapsed: 0:23:28.\n",
            "  Batch 3,240  of  14,063.    Elapsed: 0:23:45.\n",
            "  Batch 3,280  of  14,063.    Elapsed: 0:24:03.\n",
            "  Batch 3,320  of  14,063.    Elapsed: 0:24:21.\n",
            "  Batch 3,360  of  14,063.    Elapsed: 0:24:38.\n",
            "  Batch 3,400  of  14,063.    Elapsed: 0:24:56.\n",
            "  Batch 3,440  of  14,063.    Elapsed: 0:25:14.\n",
            "  Batch 3,480  of  14,063.    Elapsed: 0:25:31.\n",
            "  Batch 3,520  of  14,063.    Elapsed: 0:25:49.\n",
            "  Batch 3,560  of  14,063.    Elapsed: 0:26:07.\n",
            "  Batch 3,600  of  14,063.    Elapsed: 0:26:24.\n",
            "  Batch 3,640  of  14,063.    Elapsed: 0:26:42.\n",
            "  Batch 3,680  of  14,063.    Elapsed: 0:27:00.\n",
            "  Batch 3,720  of  14,063.    Elapsed: 0:27:17.\n",
            "  Batch 3,760  of  14,063.    Elapsed: 0:27:35.\n",
            "  Batch 3,800  of  14,063.    Elapsed: 0:27:52.\n",
            "  Batch 3,840  of  14,063.    Elapsed: 0:28:10.\n",
            "  Batch 3,880  of  14,063.    Elapsed: 0:28:28.\n",
            "  Batch 3,920  of  14,063.    Elapsed: 0:28:45.\n",
            "  Batch 3,960  of  14,063.    Elapsed: 0:29:03.\n",
            "  Batch 4,000  of  14,063.    Elapsed: 0:29:21.\n",
            "  Batch 4,040  of  14,063.    Elapsed: 0:29:38.\n",
            "  Batch 4,080  of  14,063.    Elapsed: 0:29:56.\n",
            "  Batch 4,120  of  14,063.    Elapsed: 0:30:14.\n",
            "  Batch 4,160  of  14,063.    Elapsed: 0:30:31.\n",
            "  Batch 4,200  of  14,063.    Elapsed: 0:30:49.\n",
            "  Batch 4,240  of  14,063.    Elapsed: 0:31:07.\n",
            "  Batch 4,280  of  14,063.    Elapsed: 0:31:24.\n",
            "  Batch 4,320  of  14,063.    Elapsed: 0:31:42.\n",
            "  Batch 4,360  of  14,063.    Elapsed: 0:32:00.\n",
            "  Batch 4,400  of  14,063.    Elapsed: 0:32:17.\n",
            "  Batch 4,440  of  14,063.    Elapsed: 0:32:35.\n",
            "  Batch 4,480  of  14,063.    Elapsed: 0:32:53.\n",
            "  Batch 4,520  of  14,063.    Elapsed: 0:33:10.\n",
            "  Batch 4,560  of  14,063.    Elapsed: 0:33:28.\n",
            "  Batch 4,600  of  14,063.    Elapsed: 0:33:46.\n",
            "  Batch 4,640  of  14,063.    Elapsed: 0:34:03.\n",
            "  Batch 4,680  of  14,063.    Elapsed: 0:34:21.\n",
            "  Batch 4,720  of  14,063.    Elapsed: 0:34:39.\n",
            "  Batch 4,760  of  14,063.    Elapsed: 0:34:56.\n",
            "  Batch 4,800  of  14,063.    Elapsed: 0:35:14.\n",
            "  Batch 4,840  of  14,063.    Elapsed: 0:35:32.\n",
            "  Batch 4,880  of  14,063.    Elapsed: 0:35:49.\n",
            "  Batch 4,920  of  14,063.    Elapsed: 0:36:07.\n",
            "  Batch 4,960  of  14,063.    Elapsed: 0:36:25.\n",
            "  Batch 5,000  of  14,063.    Elapsed: 0:36:42.\n",
            "  Batch 5,040  of  14,063.    Elapsed: 0:37:00.\n",
            "  Batch 5,080  of  14,063.    Elapsed: 0:37:17.\n",
            "  Batch 5,120  of  14,063.    Elapsed: 0:37:35.\n",
            "  Batch 5,160  of  14,063.    Elapsed: 0:37:53.\n",
            "  Batch 5,200  of  14,063.    Elapsed: 0:38:10.\n",
            "  Batch 5,240  of  14,063.    Elapsed: 0:38:28.\n",
            "  Batch 5,280  of  14,063.    Elapsed: 0:38:46.\n",
            "  Batch 5,320  of  14,063.    Elapsed: 0:39:03.\n",
            "  Batch 5,360  of  14,063.    Elapsed: 0:39:21.\n",
            "  Batch 5,400  of  14,063.    Elapsed: 0:39:39.\n",
            "  Batch 5,440  of  14,063.    Elapsed: 0:39:56.\n",
            "  Batch 5,480  of  14,063.    Elapsed: 0:40:14.\n",
            "  Batch 5,520  of  14,063.    Elapsed: 0:40:32.\n",
            "  Batch 5,560  of  14,063.    Elapsed: 0:40:49.\n",
            "  Batch 5,600  of  14,063.    Elapsed: 0:41:07.\n",
            "  Batch 5,640  of  14,063.    Elapsed: 0:41:24.\n",
            "  Batch 5,680  of  14,063.    Elapsed: 0:41:42.\n",
            "  Batch 5,720  of  14,063.    Elapsed: 0:42:00.\n",
            "  Batch 5,760  of  14,063.    Elapsed: 0:42:17.\n",
            "  Batch 5,800  of  14,063.    Elapsed: 0:42:35.\n",
            "  Batch 5,840  of  14,063.    Elapsed: 0:42:53.\n",
            "  Batch 5,880  of  14,063.    Elapsed: 0:43:10.\n",
            "  Batch 5,920  of  14,063.    Elapsed: 0:43:28.\n",
            "  Batch 5,960  of  14,063.    Elapsed: 0:43:46.\n",
            "  Batch 6,000  of  14,063.    Elapsed: 0:44:03.\n",
            "  Batch 6,040  of  14,063.    Elapsed: 0:44:21.\n",
            "  Batch 6,080  of  14,063.    Elapsed: 0:44:39.\n",
            "  Batch 6,120  of  14,063.    Elapsed: 0:44:56.\n",
            "  Batch 6,160  of  14,063.    Elapsed: 0:45:14.\n",
            "  Batch 6,200  of  14,063.    Elapsed: 0:45:32.\n",
            "  Batch 6,240  of  14,063.    Elapsed: 0:45:49.\n",
            "  Batch 6,280  of  14,063.    Elapsed: 0:46:07.\n",
            "  Batch 6,320  of  14,063.    Elapsed: 0:46:25.\n",
            "  Batch 6,360  of  14,063.    Elapsed: 0:46:42.\n",
            "  Batch 6,400  of  14,063.    Elapsed: 0:47:00.\n",
            "  Batch 6,440  of  14,063.    Elapsed: 0:47:17.\n",
            "  Batch 6,480  of  14,063.    Elapsed: 0:47:35.\n",
            "  Batch 6,520  of  14,063.    Elapsed: 0:47:53.\n",
            "  Batch 6,560  of  14,063.    Elapsed: 0:48:10.\n",
            "  Batch 6,600  of  14,063.    Elapsed: 0:48:28.\n",
            "  Batch 6,640  of  14,063.    Elapsed: 0:48:46.\n",
            "  Batch 6,680  of  14,063.    Elapsed: 0:49:03.\n",
            "  Batch 6,720  of  14,063.    Elapsed: 0:49:21.\n",
            "  Batch 6,760  of  14,063.    Elapsed: 0:49:39.\n",
            "  Batch 6,800  of  14,063.    Elapsed: 0:49:56.\n",
            "  Batch 6,840  of  14,063.    Elapsed: 0:50:14.\n",
            "  Batch 6,880  of  14,063.    Elapsed: 0:50:32.\n",
            "  Batch 6,920  of  14,063.    Elapsed: 0:50:49.\n",
            "  Batch 6,960  of  14,063.    Elapsed: 0:51:07.\n",
            "  Batch 7,000  of  14,063.    Elapsed: 0:51:25.\n",
            "  Batch 7,040  of  14,063.    Elapsed: 0:51:42.\n",
            "  Batch 7,080  of  14,063.    Elapsed: 0:52:00.\n",
            "  Batch 7,120  of  14,063.    Elapsed: 0:52:17.\n",
            "  Batch 7,160  of  14,063.    Elapsed: 0:52:35.\n",
            "  Batch 7,200  of  14,063.    Elapsed: 0:52:53.\n",
            "  Batch 7,240  of  14,063.    Elapsed: 0:53:10.\n",
            "  Batch 7,280  of  14,063.    Elapsed: 0:53:28.\n",
            "  Batch 7,320  of  14,063.    Elapsed: 0:53:46.\n",
            "  Batch 7,360  of  14,063.    Elapsed: 0:54:03.\n",
            "  Batch 7,400  of  14,063.    Elapsed: 0:54:21.\n",
            "  Batch 7,440  of  14,063.    Elapsed: 0:54:39.\n",
            "  Batch 7,480  of  14,063.    Elapsed: 0:54:56.\n",
            "  Batch 7,520  of  14,063.    Elapsed: 0:55:14.\n",
            "  Batch 7,560  of  14,063.    Elapsed: 0:55:32.\n",
            "  Batch 7,600  of  14,063.    Elapsed: 0:55:49.\n",
            "  Batch 7,640  of  14,063.    Elapsed: 0:56:07.\n",
            "  Batch 7,680  of  14,063.    Elapsed: 0:56:25.\n",
            "  Batch 7,720  of  14,063.    Elapsed: 0:56:42.\n",
            "  Batch 7,760  of  14,063.    Elapsed: 0:57:00.\n",
            "  Batch 7,800  of  14,063.    Elapsed: 0:57:17.\n",
            "  Batch 7,840  of  14,063.    Elapsed: 0:57:35.\n",
            "  Batch 7,880  of  14,063.    Elapsed: 0:57:53.\n",
            "  Batch 7,920  of  14,063.    Elapsed: 0:58:10.\n",
            "  Batch 7,960  of  14,063.    Elapsed: 0:58:28.\n",
            "  Batch 8,000  of  14,063.    Elapsed: 0:58:46.\n",
            "  Batch 8,040  of  14,063.    Elapsed: 0:59:03.\n",
            "  Batch 8,080  of  14,063.    Elapsed: 0:59:21.\n",
            "  Batch 8,120  of  14,063.    Elapsed: 0:59:39.\n",
            "  Batch 8,160  of  14,063.    Elapsed: 0:59:56.\n",
            "  Batch 8,200  of  14,063.    Elapsed: 1:00:14.\n",
            "  Batch 8,240  of  14,063.    Elapsed: 1:00:32.\n",
            "  Batch 8,280  of  14,063.    Elapsed: 1:00:49.\n",
            "  Batch 8,320  of  14,063.    Elapsed: 1:01:07.\n",
            "  Batch 8,360  of  14,063.    Elapsed: 1:01:25.\n",
            "  Batch 8,400  of  14,063.    Elapsed: 1:01:42.\n",
            "  Batch 8,440  of  14,063.    Elapsed: 1:02:00.\n",
            "  Batch 8,480  of  14,063.    Elapsed: 1:02:18.\n",
            "  Batch 8,520  of  14,063.    Elapsed: 1:02:35.\n",
            "  Batch 8,560  of  14,063.    Elapsed: 1:02:53.\n",
            "  Batch 8,600  of  14,063.    Elapsed: 1:03:11.\n",
            "  Batch 8,640  of  14,063.    Elapsed: 1:03:28.\n",
            "  Batch 8,680  of  14,063.    Elapsed: 1:03:46.\n",
            "  Batch 8,720  of  14,063.    Elapsed: 1:04:03.\n",
            "  Batch 8,760  of  14,063.    Elapsed: 1:04:21.\n",
            "  Batch 8,800  of  14,063.    Elapsed: 1:04:39.\n",
            "  Batch 8,840  of  14,063.    Elapsed: 1:04:56.\n",
            "  Batch 8,880  of  14,063.    Elapsed: 1:05:14.\n",
            "  Batch 8,920  of  14,063.    Elapsed: 1:05:32.\n",
            "  Batch 8,960  of  14,063.    Elapsed: 1:05:49.\n",
            "  Batch 9,000  of  14,063.    Elapsed: 1:06:07.\n",
            "  Batch 9,040  of  14,063.    Elapsed: 1:06:25.\n",
            "  Batch 9,080  of  14,063.    Elapsed: 1:06:42.\n",
            "  Batch 9,120  of  14,063.    Elapsed: 1:07:00.\n",
            "  Batch 9,160  of  14,063.    Elapsed: 1:07:18.\n",
            "  Batch 9,200  of  14,063.    Elapsed: 1:07:35.\n",
            "  Batch 9,240  of  14,063.    Elapsed: 1:07:53.\n",
            "  Batch 9,280  of  14,063.    Elapsed: 1:08:11.\n",
            "  Batch 9,320  of  14,063.    Elapsed: 1:08:28.\n",
            "  Batch 9,360  of  14,063.    Elapsed: 1:08:46.\n",
            "  Batch 9,400  of  14,063.    Elapsed: 1:09:03.\n",
            "  Batch 9,440  of  14,063.    Elapsed: 1:09:21.\n",
            "  Batch 9,480  of  14,063.    Elapsed: 1:09:39.\n",
            "  Batch 9,520  of  14,063.    Elapsed: 1:09:56.\n",
            "  Batch 9,560  of  14,063.    Elapsed: 1:10:14.\n",
            "  Batch 9,600  of  14,063.    Elapsed: 1:10:32.\n",
            "  Batch 9,640  of  14,063.    Elapsed: 1:10:49.\n",
            "  Batch 9,680  of  14,063.    Elapsed: 1:11:07.\n",
            "  Batch 9,720  of  14,063.    Elapsed: 1:11:25.\n",
            "  Batch 9,760  of  14,063.    Elapsed: 1:11:42.\n",
            "  Batch 9,800  of  14,063.    Elapsed: 1:12:00.\n",
            "  Batch 9,840  of  14,063.    Elapsed: 1:12:17.\n",
            "  Batch 9,880  of  14,063.    Elapsed: 1:12:35.\n",
            "  Batch 9,920  of  14,063.    Elapsed: 1:12:53.\n",
            "  Batch 9,960  of  14,063.    Elapsed: 1:13:10.\n",
            "  Batch 10,000  of  14,063.    Elapsed: 1:13:28.\n",
            "  Batch 10,040  of  14,063.    Elapsed: 1:13:46.\n",
            "  Batch 10,080  of  14,063.    Elapsed: 1:14:03.\n",
            "  Batch 10,120  of  14,063.    Elapsed: 1:14:21.\n",
            "  Batch 10,160  of  14,063.    Elapsed: 1:14:39.\n",
            "  Batch 10,200  of  14,063.    Elapsed: 1:14:56.\n",
            "  Batch 10,240  of  14,063.    Elapsed: 1:15:14.\n",
            "  Batch 10,280  of  14,063.    Elapsed: 1:15:32.\n",
            "  Batch 10,320  of  14,063.    Elapsed: 1:15:49.\n",
            "  Batch 10,360  of  14,063.    Elapsed: 1:16:07.\n",
            "  Batch 10,400  of  14,063.    Elapsed: 1:16:25.\n",
            "  Batch 10,440  of  14,063.    Elapsed: 1:16:42.\n",
            "  Batch 10,480  of  14,063.    Elapsed: 1:17:00.\n",
            "  Batch 10,520  of  14,063.    Elapsed: 1:17:18.\n",
            "  Batch 10,560  of  14,063.    Elapsed: 1:17:35.\n",
            "  Batch 10,600  of  14,063.    Elapsed: 1:17:53.\n",
            "  Batch 10,640  of  14,063.    Elapsed: 1:18:10.\n",
            "  Batch 10,680  of  14,063.    Elapsed: 1:18:28.\n",
            "  Batch 10,720  of  14,063.    Elapsed: 1:18:46.\n",
            "  Batch 10,760  of  14,063.    Elapsed: 1:19:03.\n",
            "  Batch 10,800  of  14,063.    Elapsed: 1:19:21.\n",
            "  Batch 10,840  of  14,063.    Elapsed: 1:19:39.\n",
            "  Batch 10,880  of  14,063.    Elapsed: 1:19:56.\n",
            "  Batch 10,920  of  14,063.    Elapsed: 1:20:14.\n",
            "  Batch 10,960  of  14,063.    Elapsed: 1:20:32.\n",
            "  Batch 11,000  of  14,063.    Elapsed: 1:20:49.\n",
            "  Batch 11,040  of  14,063.    Elapsed: 1:21:07.\n",
            "  Batch 11,080  of  14,063.    Elapsed: 1:21:25.\n",
            "  Batch 11,120  of  14,063.    Elapsed: 1:21:42.\n",
            "  Batch 11,160  of  14,063.    Elapsed: 1:22:00.\n",
            "  Batch 11,200  of  14,063.    Elapsed: 1:22:18.\n",
            "  Batch 11,240  of  14,063.    Elapsed: 1:22:35.\n",
            "  Batch 11,280  of  14,063.    Elapsed: 1:22:53.\n",
            "  Batch 11,320  of  14,063.    Elapsed: 1:23:11.\n",
            "  Batch 11,360  of  14,063.    Elapsed: 1:23:28.\n",
            "  Batch 11,400  of  14,063.    Elapsed: 1:23:46.\n",
            "  Batch 11,440  of  14,063.    Elapsed: 1:24:03.\n",
            "  Batch 11,480  of  14,063.    Elapsed: 1:24:21.\n",
            "  Batch 11,520  of  14,063.    Elapsed: 1:24:39.\n",
            "  Batch 11,560  of  14,063.    Elapsed: 1:24:56.\n",
            "  Batch 11,600  of  14,063.    Elapsed: 1:25:14.\n",
            "  Batch 11,640  of  14,063.    Elapsed: 1:25:32.\n",
            "  Batch 11,680  of  14,063.    Elapsed: 1:25:49.\n",
            "  Batch 11,720  of  14,063.    Elapsed: 1:26:07.\n",
            "  Batch 11,760  of  14,063.    Elapsed: 1:26:25.\n",
            "  Batch 11,800  of  14,063.    Elapsed: 1:26:42.\n",
            "  Batch 11,840  of  14,063.    Elapsed: 1:27:00.\n",
            "  Batch 11,880  of  14,063.    Elapsed: 1:27:18.\n",
            "  Batch 11,920  of  14,063.    Elapsed: 1:27:35.\n",
            "  Batch 11,960  of  14,063.    Elapsed: 1:27:53.\n",
            "  Batch 12,000  of  14,063.    Elapsed: 1:28:11.\n",
            "  Batch 12,040  of  14,063.    Elapsed: 1:28:28.\n",
            "  Batch 12,080  of  14,063.    Elapsed: 1:28:46.\n",
            "  Batch 12,120  of  14,063.    Elapsed: 1:29:03.\n",
            "  Batch 12,160  of  14,063.    Elapsed: 1:29:21.\n",
            "  Batch 12,200  of  14,063.    Elapsed: 1:29:39.\n",
            "  Batch 12,240  of  14,063.    Elapsed: 1:29:56.\n",
            "  Batch 12,280  of  14,063.    Elapsed: 1:30:14.\n",
            "  Batch 12,320  of  14,063.    Elapsed: 1:30:32.\n",
            "  Batch 12,360  of  14,063.    Elapsed: 1:30:49.\n",
            "  Batch 12,400  of  14,063.    Elapsed: 1:31:07.\n",
            "  Batch 12,440  of  14,063.    Elapsed: 1:31:25.\n",
            "  Batch 12,480  of  14,063.    Elapsed: 1:31:42.\n",
            "  Batch 12,520  of  14,063.    Elapsed: 1:32:00.\n",
            "  Batch 12,560  of  14,063.    Elapsed: 1:32:18.\n",
            "  Batch 12,600  of  14,063.    Elapsed: 1:32:35.\n",
            "  Batch 12,640  of  14,063.    Elapsed: 1:32:53.\n",
            "  Batch 12,680  of  14,063.    Elapsed: 1:33:11.\n",
            "  Batch 12,720  of  14,063.    Elapsed: 1:33:28.\n",
            "  Batch 12,760  of  14,063.    Elapsed: 1:33:46.\n",
            "  Batch 12,800  of  14,063.    Elapsed: 1:34:03.\n",
            "  Batch 12,840  of  14,063.    Elapsed: 1:34:21.\n",
            "  Batch 12,880  of  14,063.    Elapsed: 1:34:39.\n",
            "  Batch 12,920  of  14,063.    Elapsed: 1:34:56.\n",
            "  Batch 12,960  of  14,063.    Elapsed: 1:35:14.\n",
            "  Batch 13,000  of  14,063.    Elapsed: 1:35:32.\n",
            "  Batch 13,040  of  14,063.    Elapsed: 1:35:49.\n",
            "  Batch 13,080  of  14,063.    Elapsed: 1:36:07.\n",
            "  Batch 13,120  of  14,063.    Elapsed: 1:36:25.\n",
            "  Batch 13,160  of  14,063.    Elapsed: 1:36:42.\n",
            "  Batch 13,200  of  14,063.    Elapsed: 1:37:00.\n",
            "  Batch 13,240  of  14,063.    Elapsed: 1:37:18.\n",
            "  Batch 13,280  of  14,063.    Elapsed: 1:37:35.\n",
            "  Batch 13,320  of  14,063.    Elapsed: 1:37:53.\n",
            "  Batch 13,360  of  14,063.    Elapsed: 1:38:11.\n",
            "  Batch 13,400  of  14,063.    Elapsed: 1:38:28.\n",
            "  Batch 13,440  of  14,063.    Elapsed: 1:38:46.\n",
            "  Batch 13,480  of  14,063.    Elapsed: 1:39:03.\n",
            "  Batch 13,520  of  14,063.    Elapsed: 1:39:21.\n",
            "  Batch 13,560  of  14,063.    Elapsed: 1:39:39.\n",
            "  Batch 13,600  of  14,063.    Elapsed: 1:39:56.\n",
            "  Batch 13,640  of  14,063.    Elapsed: 1:40:14.\n",
            "  Batch 13,680  of  14,063.    Elapsed: 1:40:32.\n",
            "  Batch 13,720  of  14,063.    Elapsed: 1:40:49.\n",
            "  Batch 13,760  of  14,063.    Elapsed: 1:41:07.\n",
            "  Batch 13,800  of  14,063.    Elapsed: 1:41:25.\n",
            "  Batch 13,840  of  14,063.    Elapsed: 1:41:42.\n",
            "  Batch 13,880  of  14,063.    Elapsed: 1:42:00.\n",
            "  Batch 13,920  of  14,063.    Elapsed: 1:42:18.\n",
            "  Batch 13,960  of  14,063.    Elapsed: 1:42:35.\n",
            "  Batch 14,000  of  14,063.    Elapsed: 1:42:53.\n",
            "  Batch 14,040  of  14,063.    Elapsed: 1:43:10.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 1:43:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:03:07\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  14,063.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  14,063.    Elapsed: 0:00:35.\n",
            "  Batch   120  of  14,063.    Elapsed: 0:00:53.\n",
            "  Batch   160  of  14,063.    Elapsed: 0:01:11.\n",
            "  Batch   200  of  14,063.    Elapsed: 0:01:28.\n",
            "  Batch   240  of  14,063.    Elapsed: 0:01:46.\n",
            "  Batch   280  of  14,063.    Elapsed: 0:02:04.\n",
            "  Batch   320  of  14,063.    Elapsed: 0:02:21.\n",
            "  Batch   360  of  14,063.    Elapsed: 0:02:39.\n",
            "  Batch   400  of  14,063.    Elapsed: 0:02:57.\n",
            "  Batch   440  of  14,063.    Elapsed: 0:03:14.\n",
            "  Batch   480  of  14,063.    Elapsed: 0:03:32.\n",
            "  Batch   520  of  14,063.    Elapsed: 0:03:50.\n",
            "  Batch   560  of  14,063.    Elapsed: 0:04:07.\n",
            "  Batch   600  of  14,063.    Elapsed: 0:04:25.\n",
            "  Batch   640  of  14,063.    Elapsed: 0:04:42.\n",
            "  Batch   680  of  14,063.    Elapsed: 0:05:00.\n",
            "  Batch   720  of  14,063.    Elapsed: 0:05:18.\n",
            "  Batch   760  of  14,063.    Elapsed: 0:05:35.\n",
            "  Batch   800  of  14,063.    Elapsed: 0:05:53.\n",
            "  Batch   840  of  14,063.    Elapsed: 0:06:11.\n",
            "  Batch   880  of  14,063.    Elapsed: 0:06:28.\n",
            "  Batch   920  of  14,063.    Elapsed: 0:06:46.\n",
            "  Batch   960  of  14,063.    Elapsed: 0:07:04.\n",
            "  Batch 1,000  of  14,063.    Elapsed: 0:07:21.\n",
            "  Batch 1,040  of  14,063.    Elapsed: 0:07:39.\n",
            "  Batch 1,080  of  14,063.    Elapsed: 0:07:57.\n",
            "  Batch 1,120  of  14,063.    Elapsed: 0:08:14.\n",
            "  Batch 1,160  of  14,063.    Elapsed: 0:08:32.\n",
            "  Batch 1,200  of  14,063.    Elapsed: 0:08:49.\n",
            "  Batch 1,240  of  14,063.    Elapsed: 0:09:07.\n",
            "  Batch 1,280  of  14,063.    Elapsed: 0:09:25.\n",
            "  Batch 1,320  of  14,063.    Elapsed: 0:09:42.\n",
            "  Batch 1,360  of  14,063.    Elapsed: 0:10:00.\n",
            "  Batch 1,400  of  14,063.    Elapsed: 0:10:18.\n",
            "  Batch 1,440  of  14,063.    Elapsed: 0:10:35.\n",
            "  Batch 1,480  of  14,063.    Elapsed: 0:10:53.\n",
            "  Batch 1,520  of  14,063.    Elapsed: 0:11:11.\n",
            "  Batch 1,560  of  14,063.    Elapsed: 0:11:28.\n",
            "  Batch 1,600  of  14,063.    Elapsed: 0:11:46.\n",
            "  Batch 1,640  of  14,063.    Elapsed: 0:12:04.\n",
            "  Batch 1,680  of  14,063.    Elapsed: 0:12:21.\n",
            "  Batch 1,720  of  14,063.    Elapsed: 0:12:39.\n",
            "  Batch 1,760  of  14,063.    Elapsed: 0:12:57.\n",
            "  Batch 1,800  of  14,063.    Elapsed: 0:13:14.\n",
            "  Batch 1,840  of  14,063.    Elapsed: 0:13:32.\n",
            "  Batch 1,880  of  14,063.    Elapsed: 0:13:49.\n",
            "  Batch 1,920  of  14,063.    Elapsed: 0:14:07.\n",
            "  Batch 1,960  of  14,063.    Elapsed: 0:14:25.\n",
            "  Batch 2,000  of  14,063.    Elapsed: 0:14:42.\n",
            "  Batch 2,040  of  14,063.    Elapsed: 0:15:00.\n",
            "  Batch 2,080  of  14,063.    Elapsed: 0:15:18.\n",
            "  Batch 2,120  of  14,063.    Elapsed: 0:15:35.\n",
            "  Batch 2,160  of  14,063.    Elapsed: 0:15:53.\n",
            "  Batch 2,200  of  14,063.    Elapsed: 0:16:11.\n",
            "  Batch 2,240  of  14,063.    Elapsed: 0:16:28.\n",
            "  Batch 2,280  of  14,063.    Elapsed: 0:16:46.\n",
            "  Batch 2,320  of  14,063.    Elapsed: 0:17:04.\n",
            "  Batch 2,360  of  14,063.    Elapsed: 0:17:21.\n",
            "  Batch 2,400  of  14,063.    Elapsed: 0:17:39.\n",
            "  Batch 2,440  of  14,063.    Elapsed: 0:17:57.\n",
            "  Batch 2,480  of  14,063.    Elapsed: 0:18:14.\n",
            "  Batch 2,520  of  14,063.    Elapsed: 0:18:32.\n",
            "  Batch 2,560  of  14,063.    Elapsed: 0:18:50.\n",
            "  Batch 2,600  of  14,063.    Elapsed: 0:19:07.\n",
            "  Batch 2,640  of  14,063.    Elapsed: 0:19:25.\n",
            "  Batch 2,680  of  14,063.    Elapsed: 0:19:43.\n",
            "  Batch 2,720  of  14,063.    Elapsed: 0:20:00.\n",
            "  Batch 2,760  of  14,063.    Elapsed: 0:20:18.\n",
            "  Batch 2,800  of  14,063.    Elapsed: 0:20:36.\n",
            "  Batch 2,840  of  14,063.    Elapsed: 0:20:53.\n",
            "  Batch 2,880  of  14,063.    Elapsed: 0:21:11.\n",
            "  Batch 2,920  of  14,063.    Elapsed: 0:21:29.\n",
            "  Batch 2,960  of  14,063.    Elapsed: 0:21:46.\n",
            "  Batch 3,000  of  14,063.    Elapsed: 0:22:04.\n",
            "  Batch 3,040  of  14,063.    Elapsed: 0:22:22.\n",
            "  Batch 3,080  of  14,063.    Elapsed: 0:22:39.\n",
            "  Batch 3,120  of  14,063.    Elapsed: 0:22:57.\n",
            "  Batch 3,160  of  14,063.    Elapsed: 0:23:15.\n",
            "  Batch 3,200  of  14,063.    Elapsed: 0:23:32.\n",
            "  Batch 3,240  of  14,063.    Elapsed: 0:23:50.\n",
            "  Batch 3,280  of  14,063.    Elapsed: 0:24:08.\n",
            "  Batch 3,320  of  14,063.    Elapsed: 0:24:25.\n",
            "  Batch 3,360  of  14,063.    Elapsed: 0:24:43.\n",
            "  Batch 3,400  of  14,063.    Elapsed: 0:25:00.\n",
            "  Batch 3,440  of  14,063.    Elapsed: 0:25:18.\n",
            "  Batch 3,480  of  14,063.    Elapsed: 0:25:36.\n",
            "  Batch 3,520  of  14,063.    Elapsed: 0:25:53.\n",
            "  Batch 3,560  of  14,063.    Elapsed: 0:26:11.\n",
            "  Batch 3,600  of  14,063.    Elapsed: 0:26:29.\n",
            "  Batch 3,640  of  14,063.    Elapsed: 0:26:46.\n",
            "  Batch 3,680  of  14,063.    Elapsed: 0:27:04.\n",
            "  Batch 3,720  of  14,063.    Elapsed: 0:27:22.\n",
            "  Batch 3,760  of  14,063.    Elapsed: 0:27:39.\n",
            "  Batch 3,800  of  14,063.    Elapsed: 0:27:57.\n",
            "  Batch 3,840  of  14,063.    Elapsed: 0:28:15.\n",
            "  Batch 3,880  of  14,063.    Elapsed: 0:28:32.\n",
            "  Batch 3,920  of  14,063.    Elapsed: 0:28:50.\n",
            "  Batch 3,960  of  14,063.    Elapsed: 0:29:08.\n",
            "  Batch 4,000  of  14,063.    Elapsed: 0:29:25.\n",
            "  Batch 4,040  of  14,063.    Elapsed: 0:29:43.\n",
            "  Batch 4,080  of  14,063.    Elapsed: 0:30:01.\n",
            "  Batch 4,120  of  14,063.    Elapsed: 0:30:18.\n",
            "  Batch 4,160  of  14,063.    Elapsed: 0:30:36.\n",
            "  Batch 4,200  of  14,063.    Elapsed: 0:30:53.\n",
            "  Batch 4,240  of  14,063.    Elapsed: 0:31:11.\n",
            "  Batch 4,280  of  14,063.    Elapsed: 0:31:29.\n",
            "  Batch 4,320  of  14,063.    Elapsed: 0:31:46.\n",
            "  Batch 4,360  of  14,063.    Elapsed: 0:32:04.\n",
            "  Batch 4,400  of  14,063.    Elapsed: 0:32:22.\n",
            "  Batch 4,440  of  14,063.    Elapsed: 0:32:39.\n",
            "  Batch 4,480  of  14,063.    Elapsed: 0:32:57.\n",
            "  Batch 4,520  of  14,063.    Elapsed: 0:33:15.\n",
            "  Batch 4,560  of  14,063.    Elapsed: 0:33:32.\n",
            "  Batch 4,600  of  14,063.    Elapsed: 0:33:50.\n",
            "  Batch 4,640  of  14,063.    Elapsed: 0:34:08.\n",
            "  Batch 4,680  of  14,063.    Elapsed: 0:34:25.\n",
            "  Batch 4,720  of  14,063.    Elapsed: 0:34:43.\n",
            "  Batch 4,760  of  14,063.    Elapsed: 0:35:01.\n",
            "  Batch 4,800  of  14,063.    Elapsed: 0:35:18.\n",
            "  Batch 4,840  of  14,063.    Elapsed: 0:35:36.\n",
            "  Batch 4,880  of  14,063.    Elapsed: 0:35:54.\n",
            "  Batch 4,920  of  14,063.    Elapsed: 0:36:11.\n",
            "  Batch 4,960  of  14,063.    Elapsed: 0:36:29.\n",
            "  Batch 5,000  of  14,063.    Elapsed: 0:36:47.\n",
            "  Batch 5,040  of  14,063.    Elapsed: 0:37:04.\n",
            "  Batch 5,080  of  14,063.    Elapsed: 0:37:22.\n",
            "  Batch 5,120  of  14,063.    Elapsed: 0:37:40.\n",
            "  Batch 5,160  of  14,063.    Elapsed: 0:37:57.\n",
            "  Batch 5,200  of  14,063.    Elapsed: 0:38:15.\n",
            "  Batch 5,240  of  14,063.    Elapsed: 0:38:33.\n",
            "  Batch 5,280  of  14,063.    Elapsed: 0:38:50.\n",
            "  Batch 5,320  of  14,063.    Elapsed: 0:39:08.\n",
            "  Batch 5,360  of  14,063.    Elapsed: 0:39:26.\n",
            "  Batch 5,400  of  14,063.    Elapsed: 0:39:43.\n",
            "  Batch 5,440  of  14,063.    Elapsed: 0:40:01.\n",
            "  Batch 5,480  of  14,063.    Elapsed: 0:40:19.\n",
            "  Batch 5,520  of  14,063.    Elapsed: 0:40:36.\n",
            "  Batch 5,560  of  14,063.    Elapsed: 0:40:54.\n",
            "  Batch 5,600  of  14,063.    Elapsed: 0:41:12.\n",
            "  Batch 5,640  of  14,063.    Elapsed: 0:41:29.\n",
            "  Batch 5,680  of  14,063.    Elapsed: 0:41:47.\n",
            "  Batch 5,720  of  14,063.    Elapsed: 0:42:04.\n",
            "  Batch 5,760  of  14,063.    Elapsed: 0:42:22.\n",
            "  Batch 5,800  of  14,063.    Elapsed: 0:42:40.\n",
            "  Batch 5,840  of  14,063.    Elapsed: 0:42:57.\n",
            "  Batch 5,880  of  14,063.    Elapsed: 0:43:15.\n",
            "  Batch 5,920  of  14,063.    Elapsed: 0:43:33.\n",
            "  Batch 5,960  of  14,063.    Elapsed: 0:43:50.\n",
            "  Batch 6,000  of  14,063.    Elapsed: 0:44:08.\n",
            "  Batch 6,040  of  14,063.    Elapsed: 0:44:26.\n",
            "  Batch 6,080  of  14,063.    Elapsed: 0:44:43.\n",
            "  Batch 6,120  of  14,063.    Elapsed: 0:45:01.\n",
            "  Batch 6,160  of  14,063.    Elapsed: 0:45:19.\n",
            "  Batch 6,200  of  14,063.    Elapsed: 0:45:36.\n",
            "  Batch 6,240  of  14,063.    Elapsed: 0:45:54.\n",
            "  Batch 6,280  of  14,063.    Elapsed: 0:46:12.\n",
            "  Batch 6,320  of  14,063.    Elapsed: 0:46:29.\n",
            "  Batch 6,360  of  14,063.    Elapsed: 0:46:47.\n",
            "  Batch 6,400  of  14,063.    Elapsed: 0:47:05.\n",
            "  Batch 6,440  of  14,063.    Elapsed: 0:47:22.\n",
            "  Batch 6,480  of  14,063.    Elapsed: 0:47:40.\n",
            "  Batch 6,520  of  14,063.    Elapsed: 0:47:58.\n",
            "  Batch 6,560  of  14,063.    Elapsed: 0:48:15.\n",
            "  Batch 6,600  of  14,063.    Elapsed: 0:48:33.\n",
            "  Batch 6,640  of  14,063.    Elapsed: 0:48:51.\n",
            "  Batch 6,680  of  14,063.    Elapsed: 0:49:08.\n",
            "  Batch 6,720  of  14,063.    Elapsed: 0:49:26.\n",
            "  Batch 6,760  of  14,063.    Elapsed: 0:49:43.\n",
            "  Batch 6,800  of  14,063.    Elapsed: 0:50:01.\n",
            "  Batch 6,840  of  14,063.    Elapsed: 0:50:19.\n",
            "  Batch 6,880  of  14,063.    Elapsed: 0:50:36.\n",
            "  Batch 6,920  of  14,063.    Elapsed: 0:50:54.\n",
            "  Batch 6,960  of  14,063.    Elapsed: 0:51:12.\n",
            "  Batch 7,000  of  14,063.    Elapsed: 0:51:29.\n",
            "  Batch 7,040  of  14,063.    Elapsed: 0:51:47.\n",
            "  Batch 7,080  of  14,063.    Elapsed: 0:52:05.\n",
            "  Batch 7,120  of  14,063.    Elapsed: 0:52:22.\n",
            "  Batch 7,160  of  14,063.    Elapsed: 0:52:40.\n",
            "  Batch 7,200  of  14,063.    Elapsed: 0:52:58.\n",
            "  Batch 7,240  of  14,063.    Elapsed: 0:53:15.\n",
            "  Batch 7,280  of  14,063.    Elapsed: 0:53:33.\n",
            "  Batch 7,320  of  14,063.    Elapsed: 0:53:51.\n",
            "  Batch 7,360  of  14,063.    Elapsed: 0:54:08.\n",
            "  Batch 7,400  of  14,063.    Elapsed: 0:54:26.\n",
            "  Batch 7,440  of  14,063.    Elapsed: 0:54:44.\n",
            "  Batch 7,480  of  14,063.    Elapsed: 0:55:01.\n",
            "  Batch 7,520  of  14,063.    Elapsed: 0:55:19.\n",
            "  Batch 7,560  of  14,063.    Elapsed: 0:55:37.\n",
            "  Batch 7,600  of  14,063.    Elapsed: 0:55:54.\n",
            "  Batch 7,640  of  14,063.    Elapsed: 0:56:12.\n",
            "  Batch 7,680  of  14,063.    Elapsed: 0:56:29.\n",
            "  Batch 7,720  of  14,063.    Elapsed: 0:56:47.\n",
            "  Batch 7,760  of  14,063.    Elapsed: 0:57:05.\n",
            "  Batch 7,800  of  14,063.    Elapsed: 0:57:22.\n",
            "  Batch 7,840  of  14,063.    Elapsed: 0:57:40.\n",
            "  Batch 7,880  of  14,063.    Elapsed: 0:57:58.\n",
            "  Batch 7,920  of  14,063.    Elapsed: 0:58:15.\n",
            "  Batch 7,960  of  14,063.    Elapsed: 0:58:33.\n",
            "  Batch 8,000  of  14,063.    Elapsed: 0:58:51.\n",
            "  Batch 8,040  of  14,063.    Elapsed: 0:59:08.\n",
            "  Batch 8,080  of  14,063.    Elapsed: 0:59:26.\n",
            "  Batch 8,120  of  14,063.    Elapsed: 0:59:44.\n",
            "  Batch 8,160  of  14,063.    Elapsed: 1:00:01.\n",
            "  Batch 8,200  of  14,063.    Elapsed: 1:00:19.\n",
            "  Batch 8,240  of  14,063.    Elapsed: 1:00:36.\n",
            "  Batch 8,280  of  14,063.    Elapsed: 1:00:54.\n",
            "  Batch 8,320  of  14,063.    Elapsed: 1:01:12.\n",
            "  Batch 8,360  of  14,063.    Elapsed: 1:01:29.\n",
            "  Batch 8,400  of  14,063.    Elapsed: 1:01:47.\n",
            "  Batch 8,440  of  14,063.    Elapsed: 1:02:05.\n",
            "  Batch 8,480  of  14,063.    Elapsed: 1:02:22.\n",
            "  Batch 8,520  of  14,063.    Elapsed: 1:02:40.\n",
            "  Batch 8,560  of  14,063.    Elapsed: 1:02:58.\n",
            "  Batch 8,600  of  14,063.    Elapsed: 1:03:15.\n",
            "  Batch 8,640  of  14,063.    Elapsed: 1:03:33.\n",
            "  Batch 8,680  of  14,063.    Elapsed: 1:03:51.\n",
            "  Batch 8,720  of  14,063.    Elapsed: 1:04:08.\n",
            "  Batch 8,760  of  14,063.    Elapsed: 1:04:26.\n",
            "  Batch 8,800  of  14,063.    Elapsed: 1:04:43.\n",
            "  Batch 8,840  of  14,063.    Elapsed: 1:05:01.\n",
            "  Batch 8,880  of  14,063.    Elapsed: 1:05:19.\n",
            "  Batch 8,920  of  14,063.    Elapsed: 1:05:36.\n",
            "  Batch 8,960  of  14,063.    Elapsed: 1:05:54.\n",
            "  Batch 9,000  of  14,063.    Elapsed: 1:06:12.\n",
            "  Batch 9,040  of  14,063.    Elapsed: 1:06:29.\n",
            "  Batch 9,080  of  14,063.    Elapsed: 1:06:47.\n",
            "  Batch 9,120  of  14,063.    Elapsed: 1:07:05.\n",
            "  Batch 9,160  of  14,063.    Elapsed: 1:07:22.\n",
            "  Batch 9,200  of  14,063.    Elapsed: 1:07:40.\n",
            "  Batch 9,240  of  14,063.    Elapsed: 1:07:58.\n",
            "  Batch 9,280  of  14,063.    Elapsed: 1:08:15.\n",
            "  Batch 9,320  of  14,063.    Elapsed: 1:08:33.\n",
            "  Batch 9,360  of  14,063.    Elapsed: 1:08:51.\n",
            "  Batch 9,400  of  14,063.    Elapsed: 1:09:08.\n",
            "  Batch 9,440  of  14,063.    Elapsed: 1:09:26.\n",
            "  Batch 9,480  of  14,063.    Elapsed: 1:09:43.\n",
            "  Batch 9,520  of  14,063.    Elapsed: 1:10:01.\n",
            "  Batch 9,560  of  14,063.    Elapsed: 1:10:19.\n",
            "  Batch 9,600  of  14,063.    Elapsed: 1:10:36.\n",
            "  Batch 9,640  of  14,063.    Elapsed: 1:10:54.\n",
            "  Batch 9,680  of  14,063.    Elapsed: 1:11:12.\n",
            "  Batch 9,720  of  14,063.    Elapsed: 1:11:29.\n",
            "  Batch 9,760  of  14,063.    Elapsed: 1:11:47.\n",
            "  Batch 9,800  of  14,063.    Elapsed: 1:12:05.\n",
            "  Batch 9,840  of  14,063.    Elapsed: 1:12:22.\n",
            "  Batch 9,880  of  14,063.    Elapsed: 1:12:40.\n",
            "  Batch 9,920  of  14,063.    Elapsed: 1:12:58.\n",
            "  Batch 9,960  of  14,063.    Elapsed: 1:13:15.\n",
            "  Batch 10,000  of  14,063.    Elapsed: 1:13:33.\n",
            "  Batch 10,040  of  14,063.    Elapsed: 1:13:50.\n",
            "  Batch 10,080  of  14,063.    Elapsed: 1:14:08.\n",
            "  Batch 10,120  of  14,063.    Elapsed: 1:14:26.\n",
            "  Batch 10,160  of  14,063.    Elapsed: 1:14:43.\n",
            "  Batch 10,200  of  14,063.    Elapsed: 1:15:01.\n",
            "  Batch 10,240  of  14,063.    Elapsed: 1:15:19.\n",
            "  Batch 10,280  of  14,063.    Elapsed: 1:15:36.\n",
            "  Batch 10,320  of  14,063.    Elapsed: 1:15:54.\n",
            "  Batch 10,360  of  14,063.    Elapsed: 1:16:12.\n",
            "  Batch 10,400  of  14,063.    Elapsed: 1:16:29.\n",
            "  Batch 10,440  of  14,063.    Elapsed: 1:16:47.\n",
            "  Batch 10,480  of  14,063.    Elapsed: 1:17:05.\n",
            "  Batch 10,520  of  14,063.    Elapsed: 1:17:22.\n",
            "  Batch 10,560  of  14,063.    Elapsed: 1:17:40.\n",
            "  Batch 10,600  of  14,063.    Elapsed: 1:17:57.\n",
            "  Batch 10,640  of  14,063.    Elapsed: 1:18:15.\n",
            "  Batch 10,680  of  14,063.    Elapsed: 1:18:33.\n",
            "  Batch 10,720  of  14,063.    Elapsed: 1:18:50.\n",
            "  Batch 10,760  of  14,063.    Elapsed: 1:19:08.\n",
            "  Batch 10,800  of  14,063.    Elapsed: 1:19:26.\n",
            "  Batch 10,840  of  14,063.    Elapsed: 1:19:43.\n",
            "  Batch 10,880  of  14,063.    Elapsed: 1:20:01.\n",
            "  Batch 10,920  of  14,063.    Elapsed: 1:20:19.\n",
            "  Batch 10,960  of  14,063.    Elapsed: 1:20:36.\n",
            "  Batch 11,000  of  14,063.    Elapsed: 1:20:54.\n",
            "  Batch 11,040  of  14,063.    Elapsed: 1:21:12.\n",
            "  Batch 11,080  of  14,063.    Elapsed: 1:21:29.\n",
            "  Batch 11,120  of  14,063.    Elapsed: 1:21:47.\n",
            "  Batch 11,160  of  14,063.    Elapsed: 1:22:05.\n",
            "  Batch 11,200  of  14,063.    Elapsed: 1:22:22.\n",
            "  Batch 11,240  of  14,063.    Elapsed: 1:22:40.\n",
            "  Batch 11,280  of  14,063.    Elapsed: 1:22:57.\n",
            "  Batch 11,320  of  14,063.    Elapsed: 1:23:15.\n",
            "  Batch 11,360  of  14,063.    Elapsed: 1:23:33.\n",
            "  Batch 11,400  of  14,063.    Elapsed: 1:23:50.\n",
            "  Batch 11,440  of  14,063.    Elapsed: 1:24:08.\n",
            "  Batch 11,480  of  14,063.    Elapsed: 1:24:26.\n",
            "  Batch 11,520  of  14,063.    Elapsed: 1:24:43.\n",
            "  Batch 11,560  of  14,063.    Elapsed: 1:25:01.\n",
            "  Batch 11,600  of  14,063.    Elapsed: 1:25:19.\n",
            "  Batch 11,640  of  14,063.    Elapsed: 1:25:36.\n",
            "  Batch 11,680  of  14,063.    Elapsed: 1:25:54.\n",
            "  Batch 11,720  of  14,063.    Elapsed: 1:26:11.\n",
            "  Batch 11,760  of  14,063.    Elapsed: 1:26:29.\n",
            "  Batch 11,800  of  14,063.    Elapsed: 1:26:47.\n",
            "  Batch 11,840  of  14,063.    Elapsed: 1:27:04.\n",
            "  Batch 11,880  of  14,063.    Elapsed: 1:27:22.\n",
            "  Batch 11,920  of  14,063.    Elapsed: 1:27:40.\n",
            "  Batch 11,960  of  14,063.    Elapsed: 1:27:57.\n",
            "  Batch 12,000  of  14,063.    Elapsed: 1:28:15.\n",
            "  Batch 12,040  of  14,063.    Elapsed: 1:28:33.\n",
            "  Batch 12,080  of  14,063.    Elapsed: 1:28:50.\n",
            "  Batch 12,120  of  14,063.    Elapsed: 1:29:08.\n",
            "  Batch 12,160  of  14,063.    Elapsed: 1:29:26.\n",
            "  Batch 12,200  of  14,063.    Elapsed: 1:29:43.\n",
            "  Batch 12,240  of  14,063.    Elapsed: 1:30:01.\n",
            "  Batch 12,280  of  14,063.    Elapsed: 1:30:18.\n",
            "  Batch 12,320  of  14,063.    Elapsed: 1:30:36.\n",
            "  Batch 12,360  of  14,063.    Elapsed: 1:30:54.\n",
            "  Batch 12,400  of  14,063.    Elapsed: 1:31:11.\n",
            "  Batch 12,440  of  14,063.    Elapsed: 1:31:29.\n",
            "  Batch 12,480  of  14,063.    Elapsed: 1:31:47.\n",
            "  Batch 12,520  of  14,063.    Elapsed: 1:32:04.\n",
            "  Batch 12,560  of  14,063.    Elapsed: 1:32:22.\n",
            "  Batch 12,600  of  14,063.    Elapsed: 1:32:40.\n",
            "  Batch 12,640  of  14,063.    Elapsed: 1:32:57.\n",
            "  Batch 12,680  of  14,063.    Elapsed: 1:33:15.\n",
            "  Batch 12,720  of  14,063.    Elapsed: 1:33:32.\n",
            "  Batch 12,760  of  14,063.    Elapsed: 1:33:50.\n",
            "  Batch 12,800  of  14,063.    Elapsed: 1:34:08.\n",
            "  Batch 12,840  of  14,063.    Elapsed: 1:34:25.\n",
            "  Batch 12,880  of  14,063.    Elapsed: 1:34:43.\n",
            "  Batch 12,920  of  14,063.    Elapsed: 1:35:01.\n",
            "  Batch 12,960  of  14,063.    Elapsed: 1:35:18.\n",
            "  Batch 13,000  of  14,063.    Elapsed: 1:35:36.\n",
            "  Batch 13,040  of  14,063.    Elapsed: 1:35:54.\n",
            "  Batch 13,080  of  14,063.    Elapsed: 1:36:11.\n",
            "  Batch 13,120  of  14,063.    Elapsed: 1:36:29.\n",
            "  Batch 13,160  of  14,063.    Elapsed: 1:36:47.\n",
            "  Batch 13,200  of  14,063.    Elapsed: 1:37:04.\n",
            "  Batch 13,240  of  14,063.    Elapsed: 1:37:22.\n",
            "  Batch 13,280  of  14,063.    Elapsed: 1:37:40.\n",
            "  Batch 13,320  of  14,063.    Elapsed: 1:37:57.\n",
            "  Batch 13,360  of  14,063.    Elapsed: 1:38:15.\n",
            "  Batch 13,400  of  14,063.    Elapsed: 1:38:32.\n",
            "  Batch 13,440  of  14,063.    Elapsed: 1:38:50.\n",
            "  Batch 13,480  of  14,063.    Elapsed: 1:39:08.\n",
            "  Batch 13,520  of  14,063.    Elapsed: 1:39:25.\n",
            "  Batch 13,560  of  14,063.    Elapsed: 1:39:43.\n",
            "  Batch 13,600  of  14,063.    Elapsed: 1:40:01.\n",
            "  Batch 13,640  of  14,063.    Elapsed: 1:40:18.\n",
            "  Batch 13,680  of  14,063.    Elapsed: 1:40:36.\n",
            "  Batch 13,720  of  14,063.    Elapsed: 1:40:54.\n",
            "  Batch 13,760  of  14,063.    Elapsed: 1:41:11.\n",
            "  Batch 13,800  of  14,063.    Elapsed: 1:41:29.\n",
            "  Batch 13,840  of  14,063.    Elapsed: 1:41:47.\n",
            "  Batch 13,880  of  14,063.    Elapsed: 1:42:04.\n",
            "  Batch 13,920  of  14,063.    Elapsed: 1:42:22.\n",
            "  Batch 13,960  of  14,063.    Elapsed: 1:42:40.\n",
            "  Batch 14,000  of  14,063.    Elapsed: 1:42:57.\n",
            "  Batch 14,040  of  14,063.    Elapsed: 1:43:15.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 1:43:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.34\n",
            "  Validation took: 0:03:07\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  14,063.    Elapsed: 0:00:18.\n",
            "  Batch    80  of  14,063.    Elapsed: 0:00:35.\n",
            "  Batch   120  of  14,063.    Elapsed: 0:00:53.\n",
            "  Batch   160  of  14,063.    Elapsed: 0:01:11.\n",
            "  Batch   200  of  14,063.    Elapsed: 0:01:28.\n",
            "  Batch   240  of  14,063.    Elapsed: 0:01:46.\n",
            "  Batch   280  of  14,063.    Elapsed: 0:02:04.\n",
            "  Batch   320  of  14,063.    Elapsed: 0:02:21.\n",
            "  Batch   360  of  14,063.    Elapsed: 0:02:39.\n",
            "  Batch   400  of  14,063.    Elapsed: 0:02:57.\n",
            "  Batch   440  of  14,063.    Elapsed: 0:03:14.\n",
            "  Batch   480  of  14,063.    Elapsed: 0:03:32.\n",
            "  Batch   520  of  14,063.    Elapsed: 0:03:50.\n",
            "  Batch   560  of  14,063.    Elapsed: 0:04:07.\n",
            "  Batch   600  of  14,063.    Elapsed: 0:04:25.\n",
            "  Batch   640  of  14,063.    Elapsed: 0:04:43.\n",
            "  Batch   680  of  14,063.    Elapsed: 0:05:00.\n",
            "  Batch   720  of  14,063.    Elapsed: 0:05:18.\n",
            "  Batch   760  of  14,063.    Elapsed: 0:05:36.\n",
            "  Batch   800  of  14,063.    Elapsed: 0:05:53.\n",
            "  Batch   840  of  14,063.    Elapsed: 0:06:11.\n",
            "  Batch   880  of  14,063.    Elapsed: 0:06:28.\n",
            "  Batch   920  of  14,063.    Elapsed: 0:06:46.\n",
            "  Batch   960  of  14,063.    Elapsed: 0:07:04.\n",
            "  Batch 1,000  of  14,063.    Elapsed: 0:07:21.\n",
            "  Batch 1,040  of  14,063.    Elapsed: 0:07:39.\n",
            "  Batch 1,080  of  14,063.    Elapsed: 0:07:57.\n",
            "  Batch 1,120  of  14,063.    Elapsed: 0:08:14.\n",
            "  Batch 1,160  of  14,063.    Elapsed: 0:08:32.\n",
            "  Batch 1,200  of  14,063.    Elapsed: 0:08:50.\n",
            "  Batch 1,240  of  14,063.    Elapsed: 0:09:07.\n",
            "  Batch 1,280  of  14,063.    Elapsed: 0:09:25.\n",
            "  Batch 1,320  of  14,063.    Elapsed: 0:09:43.\n",
            "  Batch 1,360  of  14,063.    Elapsed: 0:10:00.\n",
            "  Batch 1,400  of  14,063.    Elapsed: 0:10:18.\n",
            "  Batch 1,440  of  14,063.    Elapsed: 0:10:36.\n",
            "  Batch 1,480  of  14,063.    Elapsed: 0:10:53.\n",
            "  Batch 1,520  of  14,063.    Elapsed: 0:11:11.\n",
            "  Batch 1,560  of  14,063.    Elapsed: 0:11:29.\n",
            "  Batch 1,600  of  14,063.    Elapsed: 0:11:46.\n",
            "  Batch 1,640  of  14,063.    Elapsed: 0:12:04.\n",
            "  Batch 1,680  of  14,063.    Elapsed: 0:12:22.\n",
            "  Batch 1,720  of  14,063.    Elapsed: 0:12:39.\n",
            "  Batch 1,760  of  14,063.    Elapsed: 0:12:57.\n",
            "  Batch 1,800  of  14,063.    Elapsed: 0:13:15.\n",
            "  Batch 1,840  of  14,063.    Elapsed: 0:13:32.\n",
            "  Batch 1,880  of  14,063.    Elapsed: 0:13:50.\n",
            "  Batch 1,920  of  14,063.    Elapsed: 0:14:08.\n",
            "  Batch 1,960  of  14,063.    Elapsed: 0:14:25.\n",
            "  Batch 2,000  of  14,063.    Elapsed: 0:14:43.\n",
            "  Batch 2,040  of  14,063.    Elapsed: 0:15:01.\n",
            "  Batch 2,080  of  14,063.    Elapsed: 0:15:18.\n",
            "  Batch 2,120  of  14,063.    Elapsed: 0:15:36.\n",
            "  Batch 2,160  of  14,063.    Elapsed: 0:15:54.\n",
            "  Batch 2,200  of  14,063.    Elapsed: 0:16:11.\n",
            "  Batch 2,240  of  14,063.    Elapsed: 0:16:29.\n",
            "  Batch 2,280  of  14,063.    Elapsed: 0:16:47.\n",
            "  Batch 2,320  of  14,063.    Elapsed: 0:17:04.\n",
            "  Batch 2,360  of  14,063.    Elapsed: 0:17:22.\n",
            "  Batch 2,400  of  14,063.    Elapsed: 0:17:40.\n",
            "  Batch 2,440  of  14,063.    Elapsed: 0:17:57.\n",
            "  Batch 2,480  of  14,063.    Elapsed: 0:18:15.\n",
            "  Batch 2,520  of  14,063.    Elapsed: 0:18:33.\n",
            "  Batch 2,560  of  14,063.    Elapsed: 0:18:50.\n",
            "  Batch 2,600  of  14,063.    Elapsed: 0:19:08.\n",
            "  Batch 2,640  of  14,063.    Elapsed: 0:19:26.\n",
            "  Batch 2,680  of  14,063.    Elapsed: 0:19:43.\n",
            "  Batch 2,720  of  14,063.    Elapsed: 0:20:01.\n",
            "  Batch 2,760  of  14,063.    Elapsed: 0:20:19.\n",
            "  Batch 2,800  of  14,063.    Elapsed: 0:20:36.\n",
            "  Batch 2,840  of  14,063.    Elapsed: 0:20:54.\n",
            "  Batch 2,880  of  14,063.    Elapsed: 0:21:11.\n",
            "  Batch 2,920  of  14,063.    Elapsed: 0:21:29.\n",
            "  Batch 2,960  of  14,063.    Elapsed: 0:21:47.\n",
            "  Batch 3,000  of  14,063.    Elapsed: 0:22:04.\n",
            "  Batch 3,040  of  14,063.    Elapsed: 0:22:22.\n",
            "  Batch 3,080  of  14,063.    Elapsed: 0:22:40.\n",
            "  Batch 3,120  of  14,063.    Elapsed: 0:22:57.\n",
            "  Batch 3,160  of  14,063.    Elapsed: 0:23:15.\n",
            "  Batch 3,200  of  14,063.    Elapsed: 0:23:33.\n",
            "  Batch 3,240  of  14,063.    Elapsed: 0:23:50.\n",
            "  Batch 3,280  of  14,063.    Elapsed: 0:24:08.\n",
            "  Batch 3,320  of  14,063.    Elapsed: 0:24:26.\n",
            "  Batch 3,360  of  14,063.    Elapsed: 0:24:43.\n",
            "  Batch 3,400  of  14,063.    Elapsed: 0:25:01.\n",
            "  Batch 3,440  of  14,063.    Elapsed: 0:25:19.\n",
            "  Batch 3,480  of  14,063.    Elapsed: 0:25:36.\n",
            "  Batch 3,520  of  14,063.    Elapsed: 0:25:54.\n",
            "  Batch 3,560  of  14,063.    Elapsed: 0:26:11.\n",
            "  Batch 3,600  of  14,063.    Elapsed: 0:26:29.\n",
            "  Batch 3,640  of  14,063.    Elapsed: 0:26:47.\n",
            "  Batch 3,680  of  14,063.    Elapsed: 0:27:04.\n",
            "  Batch 3,720  of  14,063.    Elapsed: 0:27:22.\n",
            "  Batch 3,760  of  14,063.    Elapsed: 0:27:40.\n",
            "  Batch 3,800  of  14,063.    Elapsed: 0:27:57.\n",
            "  Batch 3,840  of  14,063.    Elapsed: 0:28:15.\n",
            "  Batch 3,880  of  14,063.    Elapsed: 0:28:33.\n",
            "  Batch 3,920  of  14,063.    Elapsed: 0:28:50.\n",
            "  Batch 3,960  of  14,063.    Elapsed: 0:29:08.\n",
            "  Batch 4,000  of  14,063.    Elapsed: 0:29:26.\n",
            "  Batch 4,040  of  14,063.    Elapsed: 0:29:43.\n",
            "  Batch 4,080  of  14,063.    Elapsed: 0:30:01.\n",
            "  Batch 4,120  of  14,063.    Elapsed: 0:30:19.\n",
            "  Batch 4,160  of  14,063.    Elapsed: 0:30:36.\n",
            "  Batch 4,200  of  14,063.    Elapsed: 0:30:54.\n",
            "  Batch 4,240  of  14,063.    Elapsed: 0:31:12.\n",
            "  Batch 4,280  of  14,063.    Elapsed: 0:31:29.\n",
            "  Batch 4,320  of  14,063.    Elapsed: 0:31:47.\n",
            "  Batch 4,360  of  14,063.    Elapsed: 0:32:05.\n",
            "  Batch 4,400  of  14,063.    Elapsed: 0:32:22.\n",
            "  Batch 4,440  of  14,063.    Elapsed: 0:32:40.\n",
            "  Batch 4,480  of  14,063.    Elapsed: 0:32:58.\n",
            "  Batch 4,520  of  14,063.    Elapsed: 0:33:15.\n",
            "  Batch 4,560  of  14,063.    Elapsed: 0:33:33.\n",
            "  Batch 4,600  of  14,063.    Elapsed: 0:33:51.\n",
            "  Batch 4,640  of  14,063.    Elapsed: 0:34:08.\n",
            "  Batch 4,680  of  14,063.    Elapsed: 0:34:26.\n",
            "  Batch 4,720  of  14,063.    Elapsed: 0:34:44.\n",
            "  Batch 4,760  of  14,063.    Elapsed: 0:35:01.\n",
            "  Batch 4,800  of  14,063.    Elapsed: 0:35:19.\n",
            "  Batch 4,840  of  14,063.    Elapsed: 0:35:37.\n",
            "  Batch 4,880  of  14,063.    Elapsed: 0:35:54.\n",
            "  Batch 4,920  of  14,063.    Elapsed: 0:36:12.\n",
            "  Batch 4,960  of  14,063.    Elapsed: 0:36:29.\n",
            "  Batch 5,000  of  14,063.    Elapsed: 0:36:47.\n",
            "  Batch 5,040  of  14,063.    Elapsed: 0:37:05.\n",
            "  Batch 5,080  of  14,063.    Elapsed: 0:37:22.\n",
            "  Batch 5,120  of  14,063.    Elapsed: 0:37:40.\n",
            "  Batch 5,160  of  14,063.    Elapsed: 0:37:58.\n",
            "  Batch 5,200  of  14,063.    Elapsed: 0:38:15.\n",
            "  Batch 5,240  of  14,063.    Elapsed: 0:38:33.\n",
            "  Batch 5,280  of  14,063.    Elapsed: 0:38:51.\n",
            "  Batch 5,320  of  14,063.    Elapsed: 0:39:08.\n",
            "  Batch 5,360  of  14,063.    Elapsed: 0:39:26.\n",
            "  Batch 5,400  of  14,063.    Elapsed: 0:39:44.\n",
            "  Batch 5,440  of  14,063.    Elapsed: 0:40:02.\n",
            "  Batch 5,480  of  14,063.    Elapsed: 0:40:19.\n",
            "  Batch 5,520  of  14,063.    Elapsed: 0:40:37.\n",
            "  Batch 5,560  of  14,063.    Elapsed: 0:40:55.\n",
            "  Batch 5,600  of  14,063.    Elapsed: 0:41:12.\n",
            "  Batch 5,640  of  14,063.    Elapsed: 0:41:30.\n",
            "  Batch 5,680  of  14,063.    Elapsed: 0:41:48.\n",
            "  Batch 5,720  of  14,063.    Elapsed: 0:42:05.\n",
            "  Batch 5,760  of  14,063.    Elapsed: 0:42:23.\n",
            "  Batch 5,800  of  14,063.    Elapsed: 0:42:41.\n",
            "  Batch 5,840  of  14,063.    Elapsed: 0:42:58.\n",
            "  Batch 5,880  of  14,063.    Elapsed: 0:43:16.\n",
            "  Batch 5,920  of  14,063.    Elapsed: 0:43:34.\n",
            "  Batch 5,960  of  14,063.    Elapsed: 0:43:51.\n",
            "  Batch 6,000  of  14,063.    Elapsed: 0:44:09.\n",
            "  Batch 6,040  of  14,063.    Elapsed: 0:44:27.\n",
            "  Batch 6,080  of  14,063.    Elapsed: 0:44:44.\n",
            "  Batch 6,120  of  14,063.    Elapsed: 0:45:02.\n",
            "  Batch 6,160  of  14,063.    Elapsed: 0:45:20.\n",
            "  Batch 6,200  of  14,063.    Elapsed: 0:45:37.\n",
            "  Batch 6,240  of  14,063.    Elapsed: 0:45:55.\n",
            "  Batch 6,280  of  14,063.    Elapsed: 0:46:13.\n",
            "  Batch 6,320  of  14,063.    Elapsed: 0:46:30.\n",
            "  Batch 6,360  of  14,063.    Elapsed: 0:46:48.\n",
            "  Batch 6,400  of  14,063.    Elapsed: 0:47:06.\n",
            "  Batch 6,440  of  14,063.    Elapsed: 0:47:23.\n",
            "  Batch 6,480  of  14,063.    Elapsed: 0:47:41.\n",
            "  Batch 6,520  of  14,063.    Elapsed: 0:47:59.\n",
            "  Batch 6,560  of  14,063.    Elapsed: 0:48:16.\n",
            "  Batch 6,600  of  14,063.    Elapsed: 0:48:34.\n",
            "  Batch 6,640  of  14,063.    Elapsed: 0:48:52.\n",
            "  Batch 6,680  of  14,063.    Elapsed: 0:49:09.\n",
            "  Batch 6,720  of  14,063.    Elapsed: 0:49:27.\n",
            "  Batch 6,760  of  14,063.    Elapsed: 0:49:45.\n",
            "  Batch 6,800  of  14,063.    Elapsed: 0:50:02.\n",
            "  Batch 6,840  of  14,063.    Elapsed: 0:50:20.\n",
            "  Batch 6,880  of  14,063.    Elapsed: 0:50:38.\n",
            "  Batch 6,920  of  14,063.    Elapsed: 0:50:55.\n",
            "  Batch 6,960  of  14,063.    Elapsed: 0:51:13.\n",
            "  Batch 7,000  of  14,063.    Elapsed: 0:51:31.\n",
            "  Batch 7,040  of  14,063.    Elapsed: 0:51:48.\n",
            "  Batch 7,080  of  14,063.    Elapsed: 0:52:06.\n",
            "  Batch 7,120  of  14,063.    Elapsed: 0:52:24.\n",
            "  Batch 7,160  of  14,063.    Elapsed: 0:52:42.\n",
            "  Batch 7,200  of  14,063.    Elapsed: 0:52:59.\n",
            "  Batch 7,240  of  14,063.    Elapsed: 0:53:17.\n",
            "  Batch 7,280  of  14,063.    Elapsed: 0:53:35.\n",
            "  Batch 7,320  of  14,063.    Elapsed: 0:53:52.\n",
            "  Batch 7,360  of  14,063.    Elapsed: 0:54:10.\n",
            "  Batch 7,400  of  14,063.    Elapsed: 0:54:28.\n",
            "  Batch 7,440  of  14,063.    Elapsed: 0:54:45.\n",
            "  Batch 7,480  of  14,063.    Elapsed: 0:55:03.\n",
            "  Batch 7,520  of  14,063.    Elapsed: 0:55:21.\n",
            "  Batch 7,560  of  14,063.    Elapsed: 0:55:38.\n",
            "  Batch 7,600  of  14,063.    Elapsed: 0:55:56.\n",
            "  Batch 7,640  of  14,063.    Elapsed: 0:56:14.\n",
            "  Batch 7,680  of  14,063.    Elapsed: 0:56:31.\n",
            "  Batch 7,720  of  14,063.    Elapsed: 0:56:49.\n",
            "  Batch 7,760  of  14,063.    Elapsed: 0:57:07.\n",
            "  Batch 7,800  of  14,063.    Elapsed: 0:57:24.\n",
            "  Batch 7,840  of  14,063.    Elapsed: 0:57:42.\n",
            "  Batch 7,880  of  14,063.    Elapsed: 0:57:59.\n",
            "  Batch 7,920  of  14,063.    Elapsed: 0:58:17.\n",
            "  Batch 7,960  of  14,063.    Elapsed: 0:58:35.\n",
            "  Batch 8,000  of  14,063.    Elapsed: 0:58:52.\n",
            "  Batch 8,040  of  14,063.    Elapsed: 0:59:10.\n",
            "  Batch 8,080  of  14,063.    Elapsed: 0:59:28.\n",
            "  Batch 8,120  of  14,063.    Elapsed: 0:59:45.\n",
            "  Batch 8,160  of  14,063.    Elapsed: 1:00:03.\n",
            "  Batch 8,200  of  14,063.    Elapsed: 1:00:21.\n",
            "  Batch 8,240  of  14,063.    Elapsed: 1:00:38.\n",
            "  Batch 8,280  of  14,063.    Elapsed: 1:00:56.\n",
            "  Batch 8,320  of  14,063.    Elapsed: 1:01:14.\n",
            "  Batch 8,360  of  14,063.    Elapsed: 1:01:31.\n",
            "  Batch 8,400  of  14,063.    Elapsed: 1:01:49.\n",
            "  Batch 8,440  of  14,063.    Elapsed: 1:02:07.\n",
            "  Batch 8,480  of  14,063.    Elapsed: 1:02:24.\n",
            "  Batch 8,520  of  14,063.    Elapsed: 1:02:42.\n",
            "  Batch 8,560  of  14,063.    Elapsed: 1:03:00.\n",
            "  Batch 8,600  of  14,063.    Elapsed: 1:03:17.\n",
            "  Batch 8,640  of  14,063.    Elapsed: 1:03:35.\n",
            "  Batch 8,680  of  14,063.    Elapsed: 1:03:53.\n",
            "  Batch 8,720  of  14,063.    Elapsed: 1:04:10.\n",
            "  Batch 8,760  of  14,063.    Elapsed: 1:04:28.\n",
            "  Batch 8,800  of  14,063.    Elapsed: 1:04:45.\n",
            "  Batch 8,840  of  14,063.    Elapsed: 1:05:03.\n",
            "  Batch 8,880  of  14,063.    Elapsed: 1:05:21.\n",
            "  Batch 8,920  of  14,063.    Elapsed: 1:05:38.\n",
            "  Batch 8,960  of  14,063.    Elapsed: 1:05:56.\n",
            "  Batch 9,000  of  14,063.    Elapsed: 1:06:14.\n",
            "  Batch 9,040  of  14,063.    Elapsed: 1:06:31.\n",
            "  Batch 9,080  of  14,063.    Elapsed: 1:06:49.\n",
            "  Batch 9,120  of  14,063.    Elapsed: 1:07:07.\n",
            "  Batch 9,160  of  14,063.    Elapsed: 1:07:24.\n",
            "  Batch 9,200  of  14,063.    Elapsed: 1:07:42.\n",
            "  Batch 9,240  of  14,063.    Elapsed: 1:08:00.\n",
            "  Batch 9,280  of  14,063.    Elapsed: 1:08:17.\n",
            "  Batch 9,320  of  14,063.    Elapsed: 1:08:35.\n",
            "  Batch 9,360  of  14,063.    Elapsed: 1:08:53.\n",
            "  Batch 9,400  of  14,063.    Elapsed: 1:09:10.\n",
            "  Batch 9,440  of  14,063.    Elapsed: 1:09:28.\n",
            "  Batch 9,480  of  14,063.    Elapsed: 1:09:46.\n",
            "  Batch 9,520  of  14,063.    Elapsed: 1:10:03.\n",
            "  Batch 9,560  of  14,063.    Elapsed: 1:10:21.\n",
            "  Batch 9,600  of  14,063.    Elapsed: 1:10:38.\n",
            "  Batch 9,640  of  14,063.    Elapsed: 1:10:56.\n",
            "  Batch 9,680  of  14,063.    Elapsed: 1:11:14.\n",
            "  Batch 9,720  of  14,063.    Elapsed: 1:11:31.\n",
            "  Batch 9,760  of  14,063.    Elapsed: 1:11:49.\n",
            "  Batch 9,800  of  14,063.    Elapsed: 1:12:07.\n",
            "  Batch 9,840  of  14,063.    Elapsed: 1:12:24.\n",
            "  Batch 9,880  of  14,063.    Elapsed: 1:12:42.\n",
            "  Batch 9,920  of  14,063.    Elapsed: 1:13:00.\n",
            "  Batch 9,960  of  14,063.    Elapsed: 1:13:17.\n",
            "  Batch 10,000  of  14,063.    Elapsed: 1:13:35.\n",
            "  Batch 10,040  of  14,063.    Elapsed: 1:13:53.\n",
            "  Batch 10,080  of  14,063.    Elapsed: 1:14:10.\n",
            "  Batch 10,120  of  14,063.    Elapsed: 1:14:28.\n",
            "  Batch 10,160  of  14,063.    Elapsed: 1:14:46.\n",
            "  Batch 10,200  of  14,063.    Elapsed: 1:15:03.\n",
            "  Batch 10,240  of  14,063.    Elapsed: 1:15:21.\n",
            "  Batch 10,280  of  14,063.    Elapsed: 1:15:38.\n",
            "  Batch 10,320  of  14,063.    Elapsed: 1:15:56.\n",
            "  Batch 10,360  of  14,063.    Elapsed: 1:16:14.\n",
            "  Batch 10,400  of  14,063.    Elapsed: 1:16:31.\n",
            "  Batch 10,440  of  14,063.    Elapsed: 1:16:49.\n",
            "  Batch 10,480  of  14,063.    Elapsed: 1:17:07.\n",
            "  Batch 10,520  of  14,063.    Elapsed: 1:17:24.\n",
            "  Batch 10,560  of  14,063.    Elapsed: 1:17:42.\n",
            "  Batch 10,600  of  14,063.    Elapsed: 1:18:00.\n",
            "  Batch 10,640  of  14,063.    Elapsed: 1:18:17.\n",
            "  Batch 10,680  of  14,063.    Elapsed: 1:18:35.\n",
            "  Batch 10,720  of  14,063.    Elapsed: 1:18:53.\n",
            "  Batch 10,760  of  14,063.    Elapsed: 1:19:10.\n",
            "  Batch 10,800  of  14,063.    Elapsed: 1:19:28.\n",
            "  Batch 10,840  of  14,063.    Elapsed: 1:19:45.\n",
            "  Batch 10,880  of  14,063.    Elapsed: 1:20:03.\n",
            "  Batch 10,920  of  14,063.    Elapsed: 1:20:21.\n",
            "  Batch 10,960  of  14,063.    Elapsed: 1:20:38.\n",
            "  Batch 11,000  of  14,063.    Elapsed: 1:20:56.\n",
            "  Batch 11,040  of  14,063.    Elapsed: 1:21:14.\n",
            "  Batch 11,080  of  14,063.    Elapsed: 1:21:31.\n",
            "  Batch 11,120  of  14,063.    Elapsed: 1:21:49.\n",
            "  Batch 11,160  of  14,063.    Elapsed: 1:22:06.\n",
            "  Batch 11,200  of  14,063.    Elapsed: 1:22:24.\n",
            "  Batch 11,240  of  14,063.    Elapsed: 1:22:42.\n",
            "  Batch 11,280  of  14,063.    Elapsed: 1:22:59.\n",
            "  Batch 11,320  of  14,063.    Elapsed: 1:23:17.\n",
            "  Batch 11,360  of  14,063.    Elapsed: 1:23:35.\n",
            "  Batch 11,400  of  14,063.    Elapsed: 1:23:52.\n",
            "  Batch 11,440  of  14,063.    Elapsed: 1:24:10.\n",
            "  Batch 11,480  of  14,063.    Elapsed: 1:24:28.\n",
            "  Batch 11,520  of  14,063.    Elapsed: 1:24:45.\n",
            "  Batch 11,560  of  14,063.    Elapsed: 1:25:03.\n",
            "  Batch 11,600  of  14,063.    Elapsed: 1:25:21.\n",
            "  Batch 11,640  of  14,063.    Elapsed: 1:25:38.\n",
            "  Batch 11,680  of  14,063.    Elapsed: 1:25:56.\n",
            "  Batch 11,720  of  14,063.    Elapsed: 1:26:13.\n",
            "  Batch 11,760  of  14,063.    Elapsed: 1:26:31.\n",
            "  Batch 11,800  of  14,063.    Elapsed: 1:26:49.\n",
            "  Batch 11,840  of  14,063.    Elapsed: 1:27:06.\n",
            "  Batch 11,880  of  14,063.    Elapsed: 1:27:24.\n",
            "  Batch 11,920  of  14,063.    Elapsed: 1:27:42.\n",
            "  Batch 11,960  of  14,063.    Elapsed: 1:27:59.\n",
            "  Batch 12,000  of  14,063.    Elapsed: 1:28:17.\n",
            "  Batch 12,040  of  14,063.    Elapsed: 1:28:35.\n",
            "  Batch 12,080  of  14,063.    Elapsed: 1:28:52.\n",
            "  Batch 12,120  of  14,063.    Elapsed: 1:29:10.\n",
            "  Batch 12,160  of  14,063.    Elapsed: 1:29:28.\n",
            "  Batch 12,200  of  14,063.    Elapsed: 1:29:45.\n",
            "  Batch 12,240  of  14,063.    Elapsed: 1:30:03.\n",
            "  Batch 12,280  of  14,063.    Elapsed: 1:30:21.\n",
            "  Batch 12,320  of  14,063.    Elapsed: 1:30:38.\n",
            "  Batch 12,360  of  14,063.    Elapsed: 1:30:56.\n",
            "  Batch 12,400  of  14,063.    Elapsed: 1:31:13.\n",
            "  Batch 12,440  of  14,063.    Elapsed: 1:31:31.\n",
            "  Batch 12,480  of  14,063.    Elapsed: 1:31:49.\n",
            "  Batch 12,520  of  14,063.    Elapsed: 1:32:06.\n",
            "  Batch 12,560  of  14,063.    Elapsed: 1:32:24.\n",
            "  Batch 12,600  of  14,063.    Elapsed: 1:32:42.\n",
            "  Batch 12,640  of  14,063.    Elapsed: 1:32:59.\n",
            "  Batch 12,680  of  14,063.    Elapsed: 1:33:17.\n",
            "  Batch 12,720  of  14,063.    Elapsed: 1:33:35.\n",
            "  Batch 12,760  of  14,063.    Elapsed: 1:33:52.\n",
            "  Batch 12,800  of  14,063.    Elapsed: 1:34:10.\n",
            "  Batch 12,840  of  14,063.    Elapsed: 1:34:27.\n",
            "  Batch 12,880  of  14,063.    Elapsed: 1:34:45.\n",
            "  Batch 12,920  of  14,063.    Elapsed: 1:35:03.\n",
            "  Batch 12,960  of  14,063.    Elapsed: 1:35:20.\n",
            "  Batch 13,000  of  14,063.    Elapsed: 1:35:38.\n",
            "  Batch 13,040  of  14,063.    Elapsed: 1:35:56.\n",
            "  Batch 13,080  of  14,063.    Elapsed: 1:36:13.\n",
            "  Batch 13,120  of  14,063.    Elapsed: 1:36:31.\n",
            "  Batch 13,160  of  14,063.    Elapsed: 1:36:49.\n",
            "  Batch 13,200  of  14,063.    Elapsed: 1:37:06.\n",
            "  Batch 13,240  of  14,063.    Elapsed: 1:37:24.\n",
            "  Batch 13,280  of  14,063.    Elapsed: 1:37:42.\n",
            "  Batch 13,320  of  14,063.    Elapsed: 1:37:59.\n",
            "  Batch 13,360  of  14,063.    Elapsed: 1:38:17.\n",
            "  Batch 13,400  of  14,063.    Elapsed: 1:38:35.\n",
            "  Batch 13,440  of  14,063.    Elapsed: 1:38:52.\n",
            "  Batch 13,480  of  14,063.    Elapsed: 1:39:10.\n",
            "  Batch 13,520  of  14,063.    Elapsed: 1:39:28.\n",
            "  Batch 13,560  of  14,063.    Elapsed: 1:39:45.\n",
            "  Batch 13,600  of  14,063.    Elapsed: 1:40:03.\n",
            "  Batch 13,640  of  14,063.    Elapsed: 1:40:21.\n",
            "  Batch 13,680  of  14,063.    Elapsed: 1:40:38.\n",
            "  Batch 13,720  of  14,063.    Elapsed: 1:40:56.\n",
            "  Batch 13,760  of  14,063.    Elapsed: 1:41:14.\n",
            "  Batch 13,800  of  14,063.    Elapsed: 1:41:31.\n",
            "  Batch 13,840  of  14,063.    Elapsed: 1:41:49.\n",
            "  Batch 13,880  of  14,063.    Elapsed: 1:42:07.\n",
            "  Batch 13,920  of  14,063.    Elapsed: 1:42:24.\n",
            "  Batch 13,960  of  14,063.    Elapsed: 1:42:42.\n",
            "  Batch 14,000  of  14,063.    Elapsed: 1:43:00.\n",
            "  Batch 14,040  of  14,063.    Elapsed: 1:43:17.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 1:43:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:03:08\n",
            "\n",
            "Training complete!\n",
            "Total training took 5:19:35 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYo1yv1vd_f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "6b305997-9660-4141-d7d7-311173f3be74"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1:43:20</td>\n",
              "      <td>0:03:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1:43:25</td>\n",
              "      <td>0:03:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1:43:27</td>\n",
              "      <td>0:03:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.39         0.35           0.85       1:43:20         0:03:07\n",
              "2               0.31         0.34           0.86       1:43:25         0:03:07\n",
              "3               0.26         0.35           0.86       1:43:27         0:03:08"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqAQ1UtyeCLk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "ea1aab3b-1ed7-4eb0-a14b-8ecc1a242abf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEQuDi-7WDPI",
        "outputId": "e34ff4ed-279d-4d1a-d803-55a10c167ed8"
      },
      "source": [
        "sent='I give it a fuck'\n",
        "encoded=tokenizer.encode(sent,max_length=64,truncation=True,pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxh6IlJ0B6ks",
        "outputId": "b80f6975-d271-463b-cbe2-db421c6256d8"
      },
      "source": [
        "tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,           \n",
        "                        #pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',   \n",
        "                        truncation=True\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0,    87,  8337,   442,    10, 40878,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vTr9TbQCDkI"
      },
      "source": [
        "import numpy as np\n",
        "def encode_reviews( reviews):\n",
        "        token_ids = np.zeros(shape=(len(reviews), MAX_SEQ_LEN), dtype=np.int32)\n",
        "        for i, review in enumerate(reviews):\n",
        "            print(review)\n",
        "            encoded = tokenizer.encode(review, max_length=MAX_SEQ_LEN, truncation=True)\n",
        "            print(encoded)\n",
        "            token_ids[i, 0:len(encoded)] = encoded\n",
        "        attention_mask = (token_ids != 0).astype(np.int32)\n",
        "        return {\"input_ids\": token_ids, \"attention_mask\": attention_mask} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FyQx6j-Dpq8",
        "outputId": "a8acd802-2a7a-4ba5-ea17-9a41b573a8a7"
      },
      "source": [
        "encoded_output=encode_reviews(sent)\n",
        "encoded_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "[0, 87, 2]\n",
            " \n",
            "[0, 2]\n",
            "g\n",
            "[0, 706, 2]\n",
            "i\n",
            "[0, 17, 2]\n",
            "v\n",
            "[0, 81, 2]\n",
            "e\n",
            "[0, 28, 2]\n",
            " \n",
            "[0, 2]\n",
            "i\n",
            "[0, 17, 2]\n",
            "t\n",
            "[0, 808, 2]\n",
            " \n",
            "[0, 2]\n",
            "a\n",
            "[0, 10, 2]\n",
            " \n",
            "[0, 2]\n",
            "f\n",
            "[0, 1238, 2]\n",
            "u\n",
            "[0, 75, 2]\n",
            "c\n",
            "[0, 501, 2]\n",
            "k\n",
            "[0, 472, 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': array([[0, 1, 1, ..., 0, 0, 0],\n",
              "        [0, 1, 0, ..., 0, 0, 0],\n",
              "        [0, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 1, 1, ..., 0, 0, 0],\n",
              "        [0, 1, 1, ..., 0, 0, 0],\n",
              "        [0, 1, 1, ..., 0, 0, 0]], dtype=int32),\n",
              " 'input_ids': array([[  0,  87,   2, ...,   0,   0,   0],\n",
              "        [  0,   2,   0, ...,   0,   0,   0],\n",
              "        [  0, 706,   2, ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [  0,  75,   2, ...,   0,   0,   0],\n",
              "        [  0, 501,   2, ...,   0,   0,   0],\n",
              "        [  0, 472,   2, ...,   0,   0,   0]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSpshJMT3D5K",
        "outputId": "997efa92-f3bb-430d-9b7b-47acbf55a080"
      },
      "source": [
        "sent='tres bien et il est  heurex'\n",
        "MAX_SEQ_LEN=64\n",
        "def encode_func(sent):\n",
        "  encode=tokenizer.encode_plus(sent, \n",
        "                               max_length=MAX_SEQ_LEN,\n",
        "                               pad_to_max_length=True,truncation=True,\n",
        "                               return_attention_mask=True,\n",
        "                               return_tensors='pt')\n",
        "  encode.to(device)\n",
        "  return encode\n",
        "encoded_output=encode_func(sent)\n",
        "encoded_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     0,   5456,   1806,     82,    211,    437, 118166,    425,      2,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
              "              1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIbPQsPx3qUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54a7aa1-fd0b-48c4-b848-c8692f015308"
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "\n",
        "result=model(input_ids=encoded_output['input_ids'],attention_mask=encoded_output['attention_mask'])\n",
        "_,prediction=torch.max(result[0],dim=1)\n",
        "output=prediction.item()\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxG_2F0hDr9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4e024f-af09-4ed0-e61f-7cc2a01b153a"
      },
      "source": [
        "#saving model\n",
        "import os\n",
        "\n",
        "output_dir = \"/gdrive/MyDrive/twitter_sentiment/model_save\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /gdrive/MyDrive/twitter_sentiment/model_save\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/gdrive/MyDrive/twitter_sentiment/model_save/tokenizer_config.json',\n",
              " '/gdrive/MyDrive/twitter_sentiment/model_save/special_tokens_map.json',\n",
              " '/gdrive/MyDrive/twitter_sentiment/model_save/sentencepiece.bpe.model',\n",
              " '/gdrive/MyDrive/twitter_sentiment/model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7zn-VWw2BJa"
      },
      "source": [
        "'''# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "    drive.mount('/content/drive') '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZtO2Mmm2Dbi"
      },
      "source": [
        "'''# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./drive/Shared drives/BERT Fine-Tuning/\"'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSFn_pfAon1N"
      },
      "source": [
        "output_dir=\"/gdrive/MyDrive/twitter_sentiment/model_save\"\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTWVKvP72J2E"
      },
      "source": [
        "import torch\n",
        "from torch import cuda\n",
        "from transformers import XLMRobertaForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "class SentimentPredictor:\n",
        "  def __init__(self,model_weight_path,max_length=64):\n",
        "    self.device='cuda' if cuda.is_available() else 'cpu'\n",
        "    self.tokenizer=XLMRobertaTokenizer.from_pretrained(model_weight_path)\n",
        "    self.MAX_SEQ_LEN=max_length\n",
        "    self.model=XLMRobertaForSequenceClassification.from_pretrained(model_weight_path)\n",
        "    #self.model.to(self.device)\n",
        "\n",
        "  def encode_reviews(self, reviews):\n",
        "    encode=self.tokenizer.encode_plus(\n",
        "                        reviews,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = self.MAX_SEQ_LEN,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',   \n",
        "                        truncation=True\n",
        "                    )\n",
        "    #encode.to(self.device)\n",
        "    return encode\n",
        "\n",
        "  def predict(self, reviews):\n",
        "    encoded_output=self.encode_reviews(reviews)\n",
        "    result=self.model(input_ids=encoded_output['input_ids'],attention_mask=encoded_output['attention_mask'])\n",
        "    _,prediction=torch.max(result[0],dim=1)\n",
        "    output=prediction.item()\n",
        "    sentiment='Positive' if output==1 else 'Negative'\n",
        "    return sentiment\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mut-k81o715_"
      },
      "source": [
        "output_dir=\"/gdrive/MyDrive/twitter_sentiment/model_save\"\n",
        "\n",
        "sentiment=SentimentPredictor(model_weight_path=output_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "EwNn-QWe-4cD",
        "outputId": "194a3a29-ce0b-4a63-b4cc-2ba77355d551"
      },
      "source": [
        "sentiment.predict('THis is very very good')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_jQ8xw1_KqZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}